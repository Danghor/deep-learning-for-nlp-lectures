1
00:00:00,000 --> 00:00:01,000


2
00:00:03,000 --> 00:00:03,000
And

3
00:00:07,000 --> 00:00:08,000
now

4
00:00:10,000 --> 00:00:11,000
we should be ready to go.

5
00:00:12,000 --> 00:00:12,000
Okay, good.

6
00:00:12,000 --> 00:00:14,000
So good afternoon, everybody.

7
00:00:14,000 --> 00:00:16,000
Again, welcome to the third lecture of deep learning for an LP.

8
00:00:17,000 --> 00:00:21,000
Today we have like, super equipment so everybody can hear me better

9
00:00:21,000 --> 00:00:25,000
than usual, and I'm still recording on zoom as well.

10
00:00:26,000 --> 00:00:29,000
So we just start with a, so thanks for your feedback, by the way.

11
00:00:29,000 --> 00:00:32,000
And here's a couple of things I want to address.

12
00:00:32,000 --> 00:00:33,000
So microphone.

13
00:00:33,000 --> 00:00:34,000
Okay.

14
00:00:34,000 --> 00:00:35,000
So that's solved.

15
00:00:35,000 --> 00:00:36,000
If it's better.

16
00:00:37,000 --> 00:00:38,000
I'm glad to hear that.

17
00:00:39,000 --> 00:00:43,000
Some people ask what was the connection of last lecture to NLP at all?

18
00:00:43,000 --> 00:00:47,000
And I have to admit, I didn't make it clear enough, but today it will be really

19
00:00:47,000 --> 00:00:47,000
clear.

20
00:00:47,000 --> 00:00:52,000
Why are we actually interested in minimizing functions and only all these

21
00:00:52,000 --> 00:00:53,000
mathematical things.

22
00:00:53,000 --> 00:00:53,000
Okay.

23
00:00:53,000 --> 00:00:55,000
So let me just address this today.

24
00:00:55,000 --> 00:00:56,000
Apologies.

25
00:00:56,000 --> 00:01:01,000
Some people ask me for whether I can stream the thing like during, uh,

26
00:01:01,000 --> 00:01:04,000
actually recording and live, whether I could stream it on zoom.

27
00:01:05,000 --> 00:01:10,000
And the answer is not really, I'm sorry, because it's just, it's getting too

28
00:01:10,000 --> 00:01:10,000
complicated.

29
00:01:10,000 --> 00:01:14,000
It's like streaming, recording this microphone, that microphone and all these

30
00:01:14,000 --> 00:01:15,000
presentations.

31
00:01:15,000 --> 00:01:19,000
So if you can't really see what's on the screen, open up your, your slides and

32
00:01:19,000 --> 00:01:20,000
you'll follow.

33
00:01:20,000 --> 00:01:22,000
It should be fine, but I'm not planning to stream that.

34
00:01:23,000 --> 00:01:26,000
And I don't think the internet actually could work like for streaming here.

35
00:01:26,000 --> 00:01:26,000
True.

36
00:01:26,000 --> 00:01:27,000
Ad-Rome.

37
00:01:27,000 --> 00:01:27,000
I'm not sure.

38
00:01:28,000 --> 00:01:29,000
So sorry about it.

39
00:01:30,000 --> 00:01:35,000
Some people are actually thought that lecture two was either too boring or too

40
00:01:35,000 --> 00:01:36,000
hard.

41
00:01:37,000 --> 00:01:40,000
And it's kind of, it's really, it's interesting because that's the point.

42
00:01:40,000 --> 00:01:44,000
I mean, we have really like diverse background here and what are the, what's

43
00:01:44,000 --> 00:01:46,000
the required background knowledge?

44
00:01:46,000 --> 00:01:48,000
And I, I can't, I can't really tell.

45
00:01:48,000 --> 00:01:51,000
I mean, we need some little bit of programming, little bit of

46
00:01:51,000 --> 00:01:57,000
mathematicals, kind of not be scared of math, but what exactly it

47
00:01:57,000 --> 00:01:59,000
means, like which courses and so on.

48
00:01:59,000 --> 00:02:00,000
It's hard to tell.

49
00:02:00,000 --> 00:02:01,000
So we have a mixture of different backgrounds.

50
00:02:02,000 --> 00:02:06,000
What I'm trying to is to have everyone on board, like really trying to get you on

51
00:02:06,000 --> 00:02:10,000
board, even though you didn't study computer stuff or you didn't study like

52
00:02:10,000 --> 00:02:14,000
deep, deep learning before machine learning and stuff like that.

53
00:02:14,000 --> 00:02:17,000
So, so sorry.

54
00:02:17,000 --> 00:02:18,000
I mean, you have to be selective as well.

55
00:02:18,000 --> 00:02:20,000
And if it's boring, you can leave.

56
00:02:20,000 --> 00:02:20,000
That's fine.

57
00:02:22,000 --> 00:02:26,000
You cannot skip it here live because it's on YouTube on YouTube.

58
00:02:26,000 --> 00:02:27,000
You can skip it.

59
00:02:27,000 --> 00:02:28,000
Okay, good.

60
00:02:28,000 --> 00:02:31,000
So there is one, one point about a life questions.

61
00:02:31,000 --> 00:02:35,000
I'm asking you whether we should have, we could have like an app and maybe be like

62
00:02:35,000 --> 00:02:38,000
online questions and you can address us on the phone.

63
00:02:38,000 --> 00:02:39,000
It'll be awesome.

64
00:02:39,000 --> 00:02:39,000
I would love to do that.

65
00:02:39,000 --> 00:02:44,000
I would love to have all these questions, but I don't know.

66
00:02:44,000 --> 00:02:46,000
I mean, it's getting again, a little bit complicated, like

67
00:02:46,000 --> 00:02:48,000
technically it takes quite a time.

68
00:02:49,000 --> 00:02:52,000
So what I want to say, if you have any questions, what, if you feel

69
00:02:52,000 --> 00:02:55,000
shy to ask, there's, there's nothing like a stupid question, like ask whatever

70
00:02:55,000 --> 00:02:57,000
you want to ask and don't hesitate.

71
00:02:57,000 --> 00:02:57,000
It's fine.

72
00:02:58,000 --> 00:02:58,000
Right.

73
00:02:58,000 --> 00:03:01,000
Because as I said, like people have different backgrounds and different

74
00:03:01,000 --> 00:03:04,000
kind of prerequisites and knowledge.

75
00:03:04,000 --> 00:03:05,000
So feel free to ask anything.

76
00:03:06,000 --> 00:03:10,000
I will leave more time, maybe on some, some detailed things that you can think

77
00:03:10,000 --> 00:03:15,000
about it, but the app life questions, something I considered, but for technical

78
00:03:15,000 --> 00:03:19,000
reasons and a lot of preparation time, I haven't really integrated it yet.

79
00:03:19,000 --> 00:03:21,000
Maybe something to do in the, in the future.

80
00:03:22,000 --> 00:03:22,000
Okay.

81
00:03:22,000 --> 00:03:24,000
But otherwise I really appreciate your feedback.

82
00:03:24,000 --> 00:03:26,000
So I had like 12 responses, which is great.

83
00:03:26,000 --> 00:03:30,000
I would love to have a hundred, but maybe next time.

84
00:03:31,000 --> 00:03:31,000
Great.

85
00:03:31,000 --> 00:03:33,000
So what are we going to do again?

86
00:03:33,000 --> 00:03:39,000
The title of this lecture, let me just get rid of this ugly thing here.

87
00:03:42,000 --> 00:03:42,000
Get away.

88
00:03:44,000 --> 00:03:44,000
Bye.

89
00:03:44,000 --> 00:03:44,000
Get away.

90
00:03:46,000 --> 00:03:49,000
Well, no matter.

91
00:03:50,000 --> 00:03:56,000
So what I, what are you going to talk about today is the binary,

92
00:03:56,000 --> 00:03:58,000
binary text classification, right?

93
00:03:58,000 --> 00:04:01,000
And now we're getting finally into NLP.

94
00:04:02,000 --> 00:04:06,000
And what we were trying to achieve today is that, well, we're going to work

95
00:04:06,000 --> 00:04:09,000
with these super example, super easy.

96
00:04:09,000 --> 00:04:13,000
Well, to some extent, easy example task, which is binary sentiment

97
00:04:13,000 --> 00:04:16,000
classification into positive and negative.

98
00:04:16,000 --> 00:04:19,000
And if you remember from the first lecture, when we showed a couple of

99
00:04:19,000 --> 00:04:24,000
tasks in an LP there was this IMDB data set.

100
00:04:24,000 --> 00:04:25,000
So this is an example of binary classification.

101
00:04:25,000 --> 00:04:28,000
They can move me and predict whether it's positive or negative.

102
00:04:28,000 --> 00:04:28,000
Right.

103
00:04:28,000 --> 00:04:32,000
And we have this, these reviews, which are either short or long.

104
00:04:32,000 --> 00:04:36,000
And today we're going to learn a, quite a simple, but still powerful

105
00:04:36,000 --> 00:04:40,000
supervised machine learning model, which we also know as logistic regression

106
00:04:40,000 --> 00:04:41,000
or maximum entropy classifier.

107
00:04:41,000 --> 00:04:45,000
But in fact, it's already a sort of single layer neural network.

108
00:04:45,000 --> 00:04:50,000
So this, we'll building up from scratch really to deep learning

109
00:04:50,000 --> 00:04:53,000
in NLP and the, all the architectures that are coming step by step.

110
00:04:54,000 --> 00:04:57,000
So this means this is an essential and important building block

111
00:04:58,000 --> 00:05:01,000
of deep neural networks.

112
00:05:01,000 --> 00:05:02,000
Okay.

113
00:05:02,000 --> 00:05:03,000
This is what we're going to address today.

114
00:05:04,000 --> 00:05:07,000
There's one premium spot here in the first row.

115
00:05:07,000 --> 00:05:09,000
If you're not afraid.

116
00:05:11,000 --> 00:05:13,000
Well, you will see everything then.

117
00:05:13,000 --> 00:05:15,000
And if you, if you sleep here, that's fine as well.

118
00:05:15,000 --> 00:05:17,000
We had somebody slept here last time.

119
00:05:17,000 --> 00:05:18,000
And that's fine.

120
00:05:19,000 --> 00:05:21,000
No, I mean, it's after lunch.

121
00:05:21,000 --> 00:05:22,000
Come on.

122
00:05:22,000 --> 00:05:24,000
I mean, the mensa food is not good, but still the food.

123
00:05:24,000 --> 00:05:26,000
So it makes your brain kind of.

124
00:05:27,000 --> 00:05:28,000
Yeah.

125
00:05:30,000 --> 00:05:31,000
So, okay.

126
00:05:31,000 --> 00:05:34,000
But before we jumped into this task, so binary classification of movie reviews.

127
00:05:34,000 --> 00:05:37,000
What are the actual challenges of a natural language processing?

128
00:05:37,000 --> 00:05:39,000
And we should actually talk about them.

129
00:05:39,000 --> 00:05:40,000
We haven't talked about the challenges.

130
00:05:40,000 --> 00:05:43,000
Why NLP is a different from, I don't know, like computer vision.

131
00:05:44,000 --> 00:05:49,000
So there is a one thing which is ambiguity and variability of human language.

132
00:05:49,000 --> 00:05:52,000
So language is highly ambiguous.

133
00:05:52,000 --> 00:05:56,000
If you look at this example and compare, I ate pizza with friends

134
00:05:56,000 --> 00:05:58,000
and I ate pizza with police.

135
00:05:59,000 --> 00:06:03,000
If they look, they look the same on the surface, but in very different things.

136
00:06:03,000 --> 00:06:05,000
So there's some ambiguity here.

137
00:06:05,000 --> 00:06:06,000
This is syntactic ambiguity.

138
00:06:07,000 --> 00:06:07,000
Right.

139
00:06:07,000 --> 00:06:10,000
So you cannot just replace one with the other and they, they are similar.

140
00:06:10,000 --> 00:06:11,000
Not at all.

141
00:06:11,000 --> 00:06:12,000
They mean totally different things.

142
00:06:13,000 --> 00:06:18,000
Uh, language is highly variable because the core message of I ate pizza with

143
00:06:18,000 --> 00:06:21,000
friends can be expressed as well.

144
00:06:21,000 --> 00:06:24,000
Friends and I shared some pizza or the pizza was eaten by myself

145
00:06:24,000 --> 00:06:25,000
and my friends and so on.

146
00:06:25,000 --> 00:06:27,000
So there are so many ways to say the same thing.

147
00:06:27,000 --> 00:06:29,000
So this is the high variability.

148
00:06:30,000 --> 00:06:34,000
And we, as humans, we are great users of language, but we are kind of

149
00:06:35,000 --> 00:06:39,000
formally understanding and describing the rules that govern language.

150
00:06:39,000 --> 00:06:45,000
No linguistic is kind of the science of trying to do so, but, this is

151
00:06:45,000 --> 00:06:49,000
a hard task, but we actually, we use language like very freely and we understand.

152
00:06:49,000 --> 00:06:51,000
So what should we do about it?

153
00:06:51,000 --> 00:06:53,000
Well, we have supervised machine learning.

154
00:06:55,000 --> 00:06:58,000
Which is going to save, save us for nature language processing, because

155
00:06:58,000 --> 00:07:03,000
the best known set of methods for dealing with language data so far, it's something

156
00:07:04,000 --> 00:07:06,000
along supervised machine learning algorithms.

157
00:07:07,000 --> 00:07:10,000
So the supervised machine learning algorithms, they trying to learn

158
00:07:10,000 --> 00:07:17,000
patterns and regularities from a set of pre annotated input, output pairs.

159
00:07:17,000 --> 00:07:21,000
So we have some pre annotated, maybe by humans, maybe just by

160
00:07:21,000 --> 00:07:22,000
scrolling, scraping from the internet.

161
00:07:23,000 --> 00:07:24,000
We have some data and input output.

162
00:07:24,000 --> 00:07:28,000
So what, what input output will be for the, um, sentiment

163
00:07:28,000 --> 00:07:29,000
classification on IMDB?

164
00:07:30,000 --> 00:07:30,000
What's the input.

165
00:07:31,000 --> 00:07:33,000
What is the input for us here for the sentiment classification?

166
00:07:34,000 --> 00:07:34,000
Text.

167
00:07:36,000 --> 00:07:36,000
It's a text.

168
00:07:36,000 --> 00:07:37,000
Yes.

169
00:07:37,000 --> 00:07:40,000
And the output will be yes or no.

170
00:07:40,000 --> 00:07:40,000
Yeah.

171
00:07:40,000 --> 00:07:41,000
Or maybe positive or negative.

172
00:07:42,000 --> 00:07:42,000
Exactly.

173
00:07:42,000 --> 00:07:43,000
Input output.

174
00:07:43,000 --> 00:07:46,000
And we have plenty of them and we're using machine learning to, to try

175
00:07:46,000 --> 00:07:49,000
to build such, um, such algorithms.

176
00:07:50,000 --> 00:07:54,000
Which means that machine learning SLS problems were a good set of rules.

177
00:07:54,000 --> 00:07:58,000
So we can kind of hard code it like saying if there is a word such and such and so

178
00:07:58,000 --> 00:08:03,000
on, but it won't scale for this domain because annotating the expected output

179
00:08:03,000 --> 00:08:05,000
for a given input is relatively simple.

180
00:08:05,000 --> 00:08:07,000
So you read your review and you say like, yeah, it's positive.

181
00:08:07,000 --> 00:08:08,000
Sure.

182
00:08:08,000 --> 00:08:08,000
Okay.

183
00:08:08,000 --> 00:08:09,000
Positive.

184
00:08:09,000 --> 00:08:13,000
Uh, so it's easy to create data training data and hard to write rules.

185
00:08:13,000 --> 00:08:17,000
So this is where machine learning will help us, but language is

186
00:08:17,000 --> 00:08:19,000
actually even more challenging.

187
00:08:19,000 --> 00:08:22,000
So it's not like everything is shiny and nice because natural language has

188
00:08:22,000 --> 00:08:26,000
properties to make it even more challenging for machine learning.

189
00:08:27,000 --> 00:08:29,000
And there are three points about language.

190
00:08:30,000 --> 00:08:31,000
Which are hard.

191
00:08:31,000 --> 00:08:34,000
So language is discrete, compositional and sparse.

192
00:08:35,000 --> 00:08:37,000
And I'm going to address each of them in detail.

193
00:08:39,000 --> 00:08:46,000
So language is symbolic and discrete because we have the basic elements of

194
00:08:46,000 --> 00:08:48,000
written language, which are what is it?

195
00:08:48,000 --> 00:08:49,000
Characters.

196
00:08:49,000 --> 00:08:49,000
Yeah.

197
00:08:50,000 --> 00:08:54,000
And the characters form words that you know, objects or concepts, events,

198
00:08:54,000 --> 00:08:57,000
actions, and ideas, and many other things.

199
00:08:58,000 --> 00:09:02,000
But these are discrete symbols, which means that words such as hamburger or

200
00:09:02,000 --> 00:09:07,000
pizza, they each evoke in us sort of like a mental representation.

201
00:09:07,000 --> 00:09:12,000
If I tell you pizza, it does something in your brain and you see maybe the pizza.

202
00:09:12,000 --> 00:09:16,000
If I tell you men's a food, it evokes certain thing in your, in your brain as

203
00:09:16,000 --> 00:09:20,000
well, but these are distinct symbols.

204
00:09:21,000 --> 00:09:22,000
Right.

205
00:09:22,000 --> 00:09:24,000
Well, meaning is external to them.

206
00:09:24,000 --> 00:09:25,000
So they don't carry any meaning.

207
00:09:25,000 --> 00:09:27,000
The meaning is interpreted in our heads.

208
00:09:28,000 --> 00:09:30,000
There's no inherent meaning in these words.

209
00:09:31,000 --> 00:09:36,000
And there's also no inherent relation between the hamburger and pizza, which

210
00:09:36,000 --> 00:09:40,000
can be inferred from the symbols or letter themselves, right?

211
00:09:40,000 --> 00:09:44,000
I mean, hamburger is just a couple of letters and pizza is a couple of letters.

212
00:09:45,000 --> 00:09:50,000
But looking at the letters, you can't do anything about it.

213
00:09:50,000 --> 00:09:52,000
You can't say they're similar, right?

214
00:09:52,000 --> 00:09:56,000
If you change one letter, you get something similar to pizza, but it won't be that

215
00:09:56,000 --> 00:09:57,000
pizza.

216
00:09:57,000 --> 00:09:57,000
It doesn't work.

217
00:09:57,000 --> 00:10:01,000
It's just two discrete symbols, completely independent in their form, which in their

218
00:10:01,000 --> 00:10:02,000
written.

219
00:10:04,000 --> 00:10:10,000
So if you compare this to, let's say something like color in machine vision or

220
00:10:10,000 --> 00:10:14,000
acoustic signals, these are continuous, right?

221
00:10:15,000 --> 00:10:22,000
So you can use a simple mathematical operation to convert a colorful, full color

222
00:10:22,000 --> 00:10:24,000
image into grayscale.

223
00:10:25,000 --> 00:10:25,000
Right.

224
00:10:25,000 --> 00:10:31,000
And you can compare two colors based on their properties, such as huge hue and

225
00:10:31,000 --> 00:10:31,000
intensity.

226
00:10:31,000 --> 00:10:36,000
So these are continuous and they carry the meaning by themselves.

227
00:10:36,000 --> 00:10:42,000
And you can just run a function on them to create something similar or something new

228
00:10:42,000 --> 00:10:43,000
that you can compare.

229
00:10:44,000 --> 00:10:49,000
This can be done with words because there is no simple operation to move from the

230
00:10:49,000 --> 00:10:51,000
word, for example, red to the word pink.

231
00:10:52,000 --> 00:10:52,000
Right.

232
00:10:52,000 --> 00:10:59,000
I mean, you can learn, you can move from pink to red in, let's say, computer vision

233
00:10:59,000 --> 00:11:03,000
or by graphics by manipulating the values of these pixels.

234
00:11:03,000 --> 00:11:05,000
You can do that objectively, basically.

235
00:11:06,000 --> 00:11:10,000
But here in language from red to pink, you just need to know and you have to look up

236
00:11:10,000 --> 00:11:12,000
it in dictionary and stuff like that.

237
00:11:12,000 --> 00:11:14,000
So this is like what makes language different.

238
00:11:14,000 --> 00:11:15,000
This is the discreteness.

239
00:11:15,000 --> 00:11:16,000
Okay.

240
00:11:16,000 --> 00:11:17,000
Any questions so far?

241
00:11:19,000 --> 00:11:23,000
Everybody's with me that this is more complicated than we think, like how to get

242
00:11:23,000 --> 00:11:26,000
from red to pink, because these are just two different things.

243
00:11:28,000 --> 00:11:28,000
Okay, great.

244
00:11:30,000 --> 00:11:34,000
Then the second part was that language is compositional because we compose letters

245
00:11:34,000 --> 00:11:36,000
to words, to phrases, to sentences.

246
00:11:37,000 --> 00:11:41,000
And the meaning of the phrase can be larger than the meaning of the individual

247
00:11:41,000 --> 00:11:45,000
words, and they kind of follow some intricate rules.

248
00:11:46,000 --> 00:11:49,000
Examples, we know like multi-word expressions.

249
00:11:50,000 --> 00:11:55,000
New York are two words, but their meaning is maybe more than just New and New York

250
00:11:55,000 --> 00:12:01,000
together or Luke something up, phrasal words, Luke up, Luke something up is

251
00:12:01,000 --> 00:12:03,000
something different than Luke something and up.

252
00:12:04,000 --> 00:12:05,000
It's just different meaning.

253
00:12:05,000 --> 00:12:05,000
Right.

254
00:12:06,000 --> 00:12:07,000
Idioms even worse.

255
00:12:08,000 --> 00:12:08,000
Kick the bucket.

256
00:12:08,000 --> 00:12:10,000
Who knows what's kick the bucket is?

257
00:12:13,000 --> 00:12:13,000
To die.

258
00:12:13,000 --> 00:12:14,000
Yeah.

259
00:12:15,000 --> 00:12:20,000
Up to die is different meaning than compositional work to kick the bucket.

260
00:12:20,000 --> 00:12:24,000
Like if you, if you don't understand the idiom and just literally translate

261
00:12:24,000 --> 00:12:26,000
a thing like keep the bucket.

262
00:12:27,000 --> 00:12:27,000
Why?

263
00:12:28,000 --> 00:12:31,000
Makes any sense, but composition makes a different sense or blue chip.

264
00:12:31,000 --> 00:12:32,000
Who knows what's a blue chip?

265
00:12:36,000 --> 00:12:38,000
It relates to stocks, but not yet.

266
00:12:38,000 --> 00:12:41,000
This is like stocks, which are kind of safe to invest in.

267
00:12:41,000 --> 00:12:41,000
Yeah.

268
00:12:41,000 --> 00:12:45,000
Like the winner, like today's, I don't know, Google, maybe blue chip.

269
00:12:45,000 --> 00:12:45,000
Yeah.

270
00:12:46,000 --> 00:12:50,000
But it's not, if you know what blue and chip is, it doesn't tell you anything.

271
00:12:50,000 --> 00:12:51,000
What a blue chip is together.

272
00:12:51,000 --> 00:12:52,000
It's like a different meaning.

273
00:12:52,000 --> 00:12:53,000
So this is the composition.

274
00:12:54,000 --> 00:12:57,000
So to interpret the text, we need to work beyond the level of letters and words

275
00:12:57,000 --> 00:13:01,000
and look for, the segment sequences of words, such as sentences

276
00:13:01,000 --> 00:13:02,000
or even the company documents.

277
00:13:02,000 --> 00:13:03,000
And we, as humans, we do that.

278
00:13:04,000 --> 00:13:06,000
We understand this compositionality for machines.

279
00:13:06,000 --> 00:13:07,000
It's kind of tricky.

280
00:13:07,000 --> 00:13:07,000
Right.

281
00:13:09,000 --> 00:13:13,000
And the last one is data sparseness because the combinations of words

282
00:13:13,000 --> 00:13:16,000
before meanings goes basically to infinity.

283
00:13:17,000 --> 00:13:22,000
So there's so many ways you can say so many things and we get never, never,

284
00:13:22,000 --> 00:13:26,000
ever enumerate or possible valid sentences, for instance.

285
00:13:27,000 --> 00:13:29,000
I mean, there's basically infinity amount of possible sentences.

286
00:13:30,000 --> 00:13:33,000
Morphological language, the way you build words, almost infinity.

287
00:13:34,000 --> 00:13:38,000
So there's no clear way of generalizing from, for example, from one sentence to

288
00:13:38,000 --> 00:13:43,000
another, or even like defining the similarity between sentences that doesn't

289
00:13:43,000 --> 00:13:47,000
depend on their meaning and the meaning is unobserved, right?

290
00:13:47,000 --> 00:13:50,000
So the meaning is somehow you have to interpret the meaning and then you can

291
00:13:51,000 --> 00:13:55,000
say whether sentence A is similar to sentence B, but looking at just plain

292
00:13:55,000 --> 00:14:00,000
characters, well, it doesn't tell you like the, their similarity, maybe, you

293
00:14:00,000 --> 00:14:02,000
know, flipping words and stuff like that, but it's just a proxy.

294
00:14:02,000 --> 00:14:04,000
It's not like a true similarity.

295
00:14:06,000 --> 00:14:09,000
So, and the point here with the sparseness is like, even if you

296
00:14:09,000 --> 00:14:13,000
have like a huge example set, we are very likely to observe events that

297
00:14:13,000 --> 00:14:15,000
never occurred in the example set.

298
00:14:15,000 --> 00:14:17,000
And there are, that are very different.

299
00:14:17,000 --> 00:14:20,000
So the number of combinations you will see in training data,

300
00:14:21,000 --> 00:14:23,000
it's just never exhaustive enough to see everything.

301
00:14:23,000 --> 00:14:25,000
And most of the time during, when they train a model.

302
00:14:25,000 --> 00:14:28,000
So in the next year, you will see there's new words.

303
00:14:29,000 --> 00:14:34,000
Now, no, now a personal nouns, for example, models trained before COVID-19

304
00:14:35,000 --> 00:14:40,000
were very completely useless when COVID-19 hit for like better sentiment

305
00:14:40,000 --> 00:14:42,000
prediction, for example, or trend prediction, because there was a new word.

306
00:14:43,000 --> 00:14:46,000
Which was everywhere, but nobody knew the word before.

307
00:14:46,000 --> 00:14:49,000
So it's just never exhaustive enough to see everything.

308
00:14:49,000 --> 00:14:51,000
But nobody knew the word before COVID-19.

309
00:14:52,000 --> 00:14:55,000
So language evolves and is sparse.

310
00:14:56,000 --> 00:14:56,000
Okay.

311
00:14:56,000 --> 00:14:59,000
So these are the three kind of like biggest challenges.

312
00:14:59,000 --> 00:15:00,000
What makes language a little bit hard?

313
00:15:01,000 --> 00:15:02,000
Any questions to that?

314
00:15:04,000 --> 00:15:07,000
Or any other personal experiences why language is hard?

315
00:15:07,000 --> 00:15:09,000
Whoever worked on language already.

316
00:15:10,000 --> 00:15:10,000
Great.

317
00:15:10,000 --> 00:15:11,000
Okay.

318
00:15:11,000 --> 00:15:11,000
So let's move on.

319
00:15:11,000 --> 00:15:13,000
We have the, we have the scene set up.

320
00:15:14,000 --> 00:15:18,000
Now we're want to move to supervised machine learning on text data.

321
00:15:19,000 --> 00:15:22,000
And now we're getting a little bit too mathematical notation because

322
00:15:22,000 --> 00:15:23,000
we're going to use some functions.

323
00:15:28,000 --> 00:15:32,000
So, okay.

324
00:15:32,000 --> 00:15:35,000
So we're going to use scalars, vectors, symmetries.

325
00:15:35,000 --> 00:15:39,000
Now here, I kind of assume you know a little bit of linear algebra.

326
00:15:39,000 --> 00:15:43,000
So you know what a vector is and you know how to multiply or matrixes and

327
00:15:43,000 --> 00:15:46,000
you know how to multiply vector and matrix and matrices together.

328
00:15:46,000 --> 00:15:46,000
Okay.

329
00:15:47,000 --> 00:15:48,000
If this is not the case, look it up.

330
00:15:49,000 --> 00:15:53,000
It shouldn't be rocket science, but you just need to practice

331
00:15:53,000 --> 00:15:54,000
a little bit, all these things.

332
00:15:55,000 --> 00:15:59,000
So what we're going to use is a lowercase letter for scalars.

333
00:15:59,000 --> 00:16:03,000
So scalar is just a number one, two, five, and so on.

334
00:16:04,000 --> 00:16:08,000
We're going to use lowercase, bold letters for representing vectors.

335
00:16:09,000 --> 00:16:09,000
Right.

336
00:16:09,000 --> 00:16:11,000
So these, can you see the difference here in the slides?

337
00:16:11,000 --> 00:16:12,000
I guess so.

338
00:16:13,000 --> 00:16:13,000
Right.

339
00:16:13,000 --> 00:16:14,000
So these are vectors, these are scalars.

340
00:16:15,000 --> 00:16:19,000
And we're going to use bold uppercase letters for matrices.

341
00:16:20,000 --> 00:16:21,000
So these two are matrices.

342
00:16:21,000 --> 00:16:24,000
So matrices are basically two dimensional arrays.

343
00:16:26,000 --> 00:16:30,000
And well, this is how we decided to do this for, you know, for this lecture.

344
00:16:30,000 --> 00:16:35,000
And you will see many different ways of how to write a scalar, a vector of matrix.

345
00:16:35,000 --> 00:16:38,000
So maybe in physics, you would see maybe something like this would

346
00:16:38,000 --> 00:16:41,000
be a vector or many other things.

347
00:16:42,000 --> 00:16:45,000
So this is always like complex dependent.

348
00:16:45,000 --> 00:16:47,000
So we're going to use this kind of sort of notation.

349
00:16:48,000 --> 00:16:54,000
And so vectors have elements in there and we're going to use this

350
00:16:56,000 --> 00:17:01,000
parenthesis and the index operator of vectors of matrix that, for example,

351
00:17:02,000 --> 00:17:08,000
bi here in the in this index operator is the ith element of vector b.

352
00:17:09,000 --> 00:17:09,000
Right.

353
00:17:09,000 --> 00:17:14,000
And the same for indexing matrices, we're going to have i and j will be like the

354
00:17:14,000 --> 00:17:16,000
ith row and j column of matrix w.

355
00:17:16,000 --> 00:17:17,000
So this should be standard.

356
00:17:17,000 --> 00:17:18,000
Yes.

357
00:17:28,000 --> 00:17:31,000
If there is, if there will be any task, like you should write a vector in the

358
00:17:31,000 --> 00:17:36,000
exam, I'll make it either explicit or I just will accept like a common sense thing.

359
00:17:37,000 --> 00:17:37,000
Right.

360
00:17:38,000 --> 00:17:38,000
Yeah.

361
00:17:38,000 --> 00:17:38,000
How wide?

362
00:17:39,000 --> 00:17:43,000
I mean, if you can draw the difference on the exam between lowercase bold

363
00:17:43,000 --> 00:17:45,000
and lowercase, non-bold good for you.

364
00:17:45,000 --> 00:17:46,000
I mean, I'll be super happy.

365
00:17:46,000 --> 00:17:47,000
Right.

366
00:17:47,000 --> 00:17:51,000
The thing which I see on exams, like people really can't even write in capital

367
00:17:51,000 --> 00:17:53,000
letters, even like explicitly ask.

368
00:17:53,000 --> 00:17:54,000
Right.

369
00:17:54,000 --> 00:17:55,000
So I'm asking for you.

370
00:17:55,000 --> 00:17:56,000
So exam, okay.

371
00:17:56,000 --> 00:17:58,000
You can practice for exam.

372
00:17:58,000 --> 00:18:01,000
Only thing, the only thing which really matters for the exam, learn how to write

373
00:18:01,000 --> 00:18:06,000
in comic sounds because otherwise we can't read it.

374
00:18:06,000 --> 00:18:07,000
I'm sorry.

375
00:18:07,000 --> 00:18:09,000
You know, and I put it on the first page, right.

376
00:18:09,000 --> 00:18:11,000
In comic sounds, you sort of something like capital.

377
00:18:12,000 --> 00:18:14,000
So you can use anything you want.

378
00:18:14,000 --> 00:18:19,000
Then, I mean, we'll be explicit about it because this is like, you know, this is

379
00:18:19,000 --> 00:18:21,000
saying context dependent where, where you are.

380
00:18:22,000 --> 00:18:22,000
Yeah.

381
00:18:22,000 --> 00:18:23,000
Any other questions to the notation so far?

382
00:18:24,000 --> 00:18:24,000
Yes.

383
00:18:26,000 --> 00:18:29,000
Second, all zero index or one index.

384
00:18:29,000 --> 00:18:31,000
I don't think we care actually here.

385
00:18:31,000 --> 00:18:34,000
I mean, we use, I think there, we're going to use like one index.

386
00:18:35,000 --> 00:18:35,000
Yeah.

387
00:18:36,000 --> 00:18:38,000
One like mathematical is from one.

388
00:18:39,000 --> 00:18:39,000
Yeah.

389
00:18:39,000 --> 00:18:39,000
Yeah.

390
00:18:39,000 --> 00:18:40,000
That's a good point.

391
00:18:40,000 --> 00:18:43,000
But typically we don't really care because we're multiplying them together and then

392
00:18:43,000 --> 00:18:44,000
it doesn't matter if you start from zero or from one.

393
00:18:45,000 --> 00:18:45,000
Okay.

394
00:18:45,000 --> 00:18:46,000
Any other questions so far?

395
00:18:48,000 --> 00:18:48,000
Okay.

396
00:18:48,000 --> 00:18:49,000
Let's move on.

397
00:18:50,000 --> 00:18:57,000
So then we're going to have a sequences of vectors where we use also like the, use

398
00:18:57,000 --> 00:18:59,000
the index, but not in the parentheses, but just like that.

399
00:18:59,000 --> 00:19:05,000
So X one period, annual sequence of vectors, X one, X two, and so on.

400
00:19:05,000 --> 00:19:08,000
So it's basically an array of vectors sources, set of vectors.

401
00:19:09,000 --> 00:19:13,000
And we're might be concatenating vectors together, which will be denoted like that.

402
00:19:13,000 --> 00:19:22,000
So we want V2 and this is where you take one vector and add another, you know, at

403
00:19:22,000 --> 00:19:24,000
the end of the other and end up with the other vector.

404
00:19:25,000 --> 00:19:25,000
Yes.

405
00:19:25,000 --> 00:19:26,000
So question here.

406
00:19:30,000 --> 00:19:34,000
So, and the next stop is coming to be, we're going to use row vectors.

407
00:19:34,000 --> 00:19:35,000
That's a great question.

408
00:19:35,000 --> 00:19:36,000
Great timing.

409
00:19:36,000 --> 00:19:39,000
I mean, if you read that before, if you didn't read it before, this is great timing.

410
00:19:40,000 --> 00:19:42,000
Where were you sitting last time here?

411
00:19:43,000 --> 00:19:45,000
So you're the guy who always, you know, it's like five seconds before and

412
00:19:45,000 --> 00:19:46,000
asking the question is coming.

413
00:19:46,000 --> 00:19:46,000
Yeah.

414
00:19:46,000 --> 00:19:47,000
I remember you.

415
00:19:47,000 --> 00:19:48,000
This is cool.

416
00:19:48,000 --> 00:19:48,000
Okay.

417
00:19:48,000 --> 00:19:50,000
It looks like we practice that, right?

418
00:19:50,000 --> 00:19:52,000
So like this bridge to the next topic.

419
00:19:53,000 --> 00:19:57,000
We're so there's so many notations, but we're going to use, and maybe a little

420
00:19:57,000 --> 00:20:02,000
bit like unorthodox, we're going to use we're going to use row vectors.

421
00:20:03,000 --> 00:20:05,000
So vector is basically a list.

422
00:20:06,000 --> 00:20:10,000
So here's an example of, you know, dimension five, and this is our vector.

423
00:20:10,000 --> 00:20:13,000
So it's a row vector, which is simply lists or one year of numbers.

424
00:20:14,000 --> 00:20:19,000
Typically mathematics, you will see like, oh, vector vector is a column vector.

425
00:20:21,000 --> 00:20:24,000
No one, two, three, four, five.

426
00:20:24,000 --> 00:20:28,000
And in a text you would write, oh, X T I'm sorry.

427
00:20:29,000 --> 00:20:33,000
X is one, two, three friends post.

428
00:20:33,000 --> 00:20:35,000
This would be like on a line.

429
00:20:35,000 --> 00:20:38,000
We're going to save this effort and we're going to just use pretend

430
00:20:38,000 --> 00:20:40,000
these are just row vectors.

431
00:20:40,000 --> 00:20:40,000
Okay.

432
00:20:41,000 --> 00:20:45,000
So this is a decision design choice we're using.

433
00:20:54,000 --> 00:20:54,000
Okay.

434
00:20:54,000 --> 00:20:55,000
What's the, okay.

435
00:20:55,000 --> 00:20:56,000
Concatenation versus two vectors.

436
00:20:57,000 --> 00:21:00,000
So in the concatenation, let me just delete that.

437
00:21:02,000 --> 00:21:02,000
No, no, no.

438
00:21:02,000 --> 00:21:09,000
It's just, it's basically saying if you have like vector, so X one is one, two,

439
00:21:09,000 --> 00:21:19,000
three, and X two is four and five, then their concatenation X one X two is going

440
00:21:19,000 --> 00:21:23,000
to be just one vector one, two, three, four, five.

441
00:21:24,000 --> 00:21:26,000
We just take them after one each other.

442
00:21:27,000 --> 00:21:27,000
Yeah.

443
00:21:27,000 --> 00:21:28,000
Okay, cool.

444
00:21:29,000 --> 00:21:31,000
Any other questions to the notation?

445
00:21:33,000 --> 00:21:33,000
Great.

446
00:21:33,000 --> 00:21:35,000
So multiplication example here.

447
00:21:35,000 --> 00:21:36,000
Yes.

448
00:21:36,000 --> 00:21:36,000
Okay.

449
00:21:37,000 --> 00:21:43,000
So we're going to be multiplying vectors and row vectors and matrices.

450
00:21:44,000 --> 00:21:45,000
And here's an example.

451
00:21:45,000 --> 00:21:50,000
So we have a vector of dimension D in it has some meaning, which will be clear

452
00:21:50,000 --> 00:21:52,000
later, but you know, as some dimension.

453
00:21:52,000 --> 00:21:57,000
Then we have a matrix W, which is also the in times the out.

454
00:21:57,000 --> 00:22:00,000
So two dimensional matrix basically.

455
00:22:01,000 --> 00:22:03,000
And we have vector B of dimension D out.

456
00:22:04,000 --> 00:22:09,000
And we're going to compute the output Y, which is this, this equation.

457
00:22:09,000 --> 00:22:13,000
So what we're going to do is we multiply the vector by matrix and add another

458
00:22:14,000 --> 00:22:18,000
vector, okay, so in a year, the example is that for these actual numbers, like

459
00:22:18,000 --> 00:22:22,000
dimension in a three and dimension now is two means that we're going to take this

460
00:22:22,000 --> 00:22:26,000
vector X, which is three dimensional.

461
00:22:27,000 --> 00:22:34,000
Multiply by three times two matrix, which gives us what, what is, what will

462
00:22:34,000 --> 00:22:35,000
be the output of this computation?

463
00:22:36,000 --> 00:22:37,000
What will be the dimension?

464
00:22:39,000 --> 00:22:41,000
You multiply vector by this matrix.

465
00:22:42,000 --> 00:22:44,000
So three vector times three times two matrix.

466
00:22:44,000 --> 00:22:45,000
What's going to be the result?

467
00:22:45,000 --> 00:22:45,000
Yeah.

468
00:22:47,000 --> 00:22:48,000
It's going to be a vector of two elements.

469
00:22:48,000 --> 00:22:49,000
Exactly.

470
00:22:49,000 --> 00:22:54,000
It's going to be a vector of two elements.

471
00:22:54,000 --> 00:22:55,000
Exactly.

472
00:22:56,000 --> 00:23:00,000
And then we're going to add it to this vector and we can, you know, add two

473
00:23:00,000 --> 00:23:03,000
vectors together if they have some dimension, then we end up with this two

474
00:23:03,000 --> 00:23:08,000
dimensional vector while I'm using the in and the out, as you see here.

475
00:23:08,000 --> 00:23:09,000
So the end will be the input here.

476
00:23:09,000 --> 00:23:14,000
So the input dimension, which will multiply by this matrix to the output

477
00:23:14,000 --> 00:23:17,000
dimension, which is here too, right?

478
00:23:17,000 --> 00:23:19,000
This is the output of the, of the multiplication.

479
00:23:20,000 --> 00:23:23,000
And then we're just summing up vectors to get this.

480
00:23:23,000 --> 00:23:25,000
Any question to this, what we are doing?

481
00:23:25,000 --> 00:23:28,000
Because typically, so typically you can have multiplication of

482
00:23:28,000 --> 00:23:31,000
matrices the other way around.

483
00:23:31,000 --> 00:23:40,000
So you would also, you can also write X is the W, the matrix times X plus B.

484
00:23:41,000 --> 00:23:44,000
And I think like in mathematics, you actually write this, like you start

485
00:23:44,000 --> 00:23:49,000
multiplying first matrix by vector, which is also fine, but then you have to

486
00:23:49,000 --> 00:23:52,000
pay attention to these two dimensions, whether it's a row vector and column

487
00:23:52,000 --> 00:23:58,000
vector, and we're using this kind of little bit unorthodox thing because

488
00:23:58,000 --> 00:24:00,000
this is coming, typically this is coming in.

489
00:24:00,000 --> 00:24:02,000
So this is a vector coming in.

490
00:24:02,000 --> 00:24:10,000
Then you have the matrix, which has the, so in times in times out and out, and

491
00:24:10,000 --> 00:24:11,000
you end up with the out dimension.

492
00:24:12,000 --> 00:24:12,000
Right?

493
00:24:12,000 --> 00:24:13,000
Yes.

494
00:24:13,000 --> 00:24:13,000
Question.

495
00:24:14,000 --> 00:24:14,000
Yes.

496
00:24:22,000 --> 00:24:22,000
Yes.

497
00:24:22,000 --> 00:24:23,000
Is it correct?

498
00:24:24,000 --> 00:24:28,000
Three rows and two, because you take, how do you multiply vector by matrix?

499
00:24:28,000 --> 00:24:33,000
This one with this one, plus this one with this one, plus this one with

500
00:24:33,000 --> 00:24:36,000
this one will give you the first.

501
00:24:37,000 --> 00:24:42,000
Then you go this one times this one, plus this time times this one, plus this one

502
00:24:42,000 --> 00:24:44,000
times this one will give you the second one.

503
00:24:58,000 --> 00:24:58,000
Okay.

504
00:24:59,000 --> 00:24:59,000
Yeah.

505
00:25:02,000 --> 00:25:04,000
So I I'm almost sure that this is correct.

506
00:25:04,000 --> 00:25:06,000
Like 99% sure this is correct.

507
00:25:06,000 --> 00:25:09,000
Multiplication of a vector by matrix.

508
00:25:10,000 --> 00:25:13,000
And you might have different kind of internal representation of multiplication

509
00:25:13,000 --> 00:25:18,000
of matrices and vectors, which is fine, but this has a meaning actually.

510
00:25:18,000 --> 00:25:19,000
You have a vector.

511
00:25:19,000 --> 00:25:20,000
Okay.

512
00:25:20,000 --> 00:25:21,000
This is interesting point.

513
00:25:21,000 --> 00:25:23,000
So you have a vector and multiply by a matrix.

514
00:25:24,000 --> 00:25:26,000
What are you doing?

515
00:25:27,000 --> 00:25:27,000
What is it?

516
00:25:30,000 --> 00:25:32,000
You have a vector, which might be a vector.

517
00:25:32,000 --> 00:25:32,000
Sorry.

518
00:25:32,000 --> 00:25:32,000
Yeah.

519
00:25:32,000 --> 00:25:37,000
It might be, let me just reiterate, which might be a vector in a, in a space.

520
00:25:37,000 --> 00:25:39,000
And you multiply by a matrix.

521
00:25:40,000 --> 00:25:40,000
What is it?

522
00:25:42,000 --> 00:25:43,000
Sorry.

523
00:25:43,000 --> 00:25:44,000
You were, you were first like behind you.

524
00:25:48,000 --> 00:25:48,000
Okay.

525
00:25:48,000 --> 00:25:49,000
Yes.

526
00:25:49,000 --> 00:25:50,000
So you first.

527
00:25:52,000 --> 00:25:53,000
It's a linear transformation.

528
00:25:54,000 --> 00:25:54,000
Yes.

529
00:25:54,000 --> 00:25:55,000
It's a.

530
00:25:59,000 --> 00:26:00,000
Well, in a way.

531
00:26:00,000 --> 00:26:01,000
Yeah.

532
00:26:01,000 --> 00:26:06,000
But I, it is some, there is some weighted sum exactly because you do

533
00:26:07,000 --> 00:26:08,000
linear weighting.

534
00:26:08,000 --> 00:26:09,000
So it's the same thing, right?

535
00:26:10,000 --> 00:26:12,000
It's a linear transformation, right?

536
00:26:12,000 --> 00:26:12,000
What does it mean?

537
00:26:12,000 --> 00:26:14,000
What is the linear transformation?

538
00:26:18,000 --> 00:26:18,000
Exactly.

539
00:26:20,000 --> 00:26:20,000
It's a projection.

540
00:26:21,000 --> 00:26:25,000
You're projecting from one space to another space.

541
00:26:26,000 --> 00:26:29,000
This is the core of linear algebra, basically.

542
00:26:29,000 --> 00:26:30,000
So there's some basis in there.

543
00:26:30,000 --> 00:26:35,000
And so you can go really wild about it, but basically here we have this vector.

544
00:26:36,000 --> 00:26:40,000
And by multiplying by this matrix, we're projecting this from three

545
00:26:40,000 --> 00:26:42,000
dimensions into two dimensions.

546
00:26:43,000 --> 00:26:47,000
What could be a projection of two or three dimensions into two dimensions?

547
00:26:47,000 --> 00:26:47,000
What is it?

548
00:26:48,000 --> 00:26:48,000
If this is linear.

549
00:26:50,000 --> 00:26:50,000
Yeah.

550
00:26:50,000 --> 00:26:51,000
Like a computer game.

551
00:26:51,000 --> 00:26:51,000
Exactly.

552
00:26:52,000 --> 00:26:56,000
You just put like three worlds into two, two, two, you know, two dimensions.

553
00:26:56,000 --> 00:26:58,000
How do you do that by projecting through a matrix?

554
00:27:00,000 --> 00:27:00,000
Nothing more.

555
00:27:01,000 --> 00:27:03,000
And also it's a linear, linear transformation.

556
00:27:03,000 --> 00:27:04,000
So it's a linear map.

557
00:27:04,000 --> 00:27:07,000
So there's some properties as kind of like the distances are kind of

558
00:27:07,000 --> 00:27:09,000
preserved and scaled and stuff like that.

559
00:27:09,000 --> 00:27:11,000
So that's why we're doing this.

560
00:27:11,000 --> 00:27:13,000
Like we're taking it as an input vector.

561
00:27:13,000 --> 00:27:14,000
I want some output vector.

562
00:27:14,000 --> 00:27:17,000
So I'm multiplying by projection matrix and then something comes out.

563
00:27:18,000 --> 00:27:18,000
Okay.

564
00:27:19,000 --> 00:27:19,000
Great.

565
00:27:19,000 --> 00:27:20,000
Any questions to that?

566
00:27:23,000 --> 00:27:24,000
Sounds perfect.

567
00:27:24,000 --> 00:27:27,000
So let's move on because we might have even, yeah, okay.

568
00:27:27,000 --> 00:27:28,000
There's one.

569
00:27:28,000 --> 00:27:30,000
We can simplify things.

570
00:27:30,000 --> 00:27:35,000
So here we are going to have the output dimensions going to be of dimension one.

571
00:27:35,000 --> 00:27:37,000
So we want to produce a scalar.

572
00:27:37,000 --> 00:27:38,000
Right?

573
00:27:38,000 --> 00:27:41,000
So now the input vector is still the same.

574
00:27:41,000 --> 00:27:45,000
So we have three dimensional vector and multiply by three times one

575
00:27:45,000 --> 00:27:47,000
matrix, which gives us what?

576
00:27:49,000 --> 00:27:53,000
So this time, this gives us a scalar.

577
00:27:53,000 --> 00:27:54,000
Yes.

578
00:27:55,000 --> 00:27:58,000
Which we then add to another scalar and get a scalar out of it.

579
00:27:59,000 --> 00:27:59,000
Right.

580
00:27:59,000 --> 00:28:01,000
And we can kind of make it easier.

581
00:28:01,000 --> 00:28:05,000
This, because this is a very nasty matrix, like three times one.

582
00:28:05,000 --> 00:28:06,000
Oh, that's ugly.

583
00:28:06,000 --> 00:28:12,000
So we, we kind of use the dot product here instead and transfer transform

584
00:28:12,000 --> 00:28:14,000
this matrix into a row vector.

585
00:28:14,000 --> 00:28:16,000
So this will become basically this.

586
00:28:17,000 --> 00:28:22,000
And here we have two row vectors and this operation is the, the dot product.

587
00:28:23,000 --> 00:28:27,000
It's basically taking each element multiplying together and summing up.

588
00:28:27,000 --> 00:28:28,000
Right.

589
00:28:28,000 --> 00:28:32,000
So the dot product of two vectors is you iterate over all elements and just

590
00:28:32,000 --> 00:28:37,000
multiply the, multiply the values of the positions.

591
00:28:37,000 --> 00:28:39,000
So everybody knows the dot product.

592
00:28:40,000 --> 00:28:43,000
If not, then look it up, but there's nothing, nothing shouldn't

593
00:28:43,000 --> 00:28:45,000
mean nothing complicated about it.

594
00:28:45,000 --> 00:28:49,000
So here we say, yeah, okay, let's, you know, let's make a dot product and

595
00:28:50,000 --> 00:28:52,000
to get a scalar and then there's a scalar.

596
00:28:52,000 --> 00:28:54,000
So these two things are equivalent.

597
00:28:55,000 --> 00:28:58,000
But this is just much easier to write because you don't have to hassle with

598
00:28:58,000 --> 00:28:59,000
these, you know, three times one matrix.

599
00:29:00,000 --> 00:29:01,000
Okay.

600
00:29:02,000 --> 00:29:03,000
Is it clear enough?

601
00:29:04,000 --> 00:29:04,000
Any question?

602
00:29:13,000 --> 00:29:13,000
Good.

603
00:29:14,000 --> 00:29:18,000
So these are the basics that I think this is the, the only thing you need from

604
00:29:18,000 --> 00:29:22,000
linear algebra for deep learning actually, how to multiply vector by matrix.

605
00:29:22,000 --> 00:29:24,000
And that a matrix is a linear transformation.

606
00:29:24,000 --> 00:29:25,000
It has a meaning.

607
00:29:25,000 --> 00:29:27,000
Linear transformation as a meaning.

608
00:29:28,000 --> 00:29:29,000
Okay.

609
00:29:29,000 --> 00:29:32,000
So then we have the mathematical foundations here, which we will need

610
00:29:32,000 --> 00:29:37,000
today and let's move to supervised classification setup.

611
00:29:37,000 --> 00:29:39,000
So what are we trying to achieve today?

612
00:29:39,000 --> 00:29:42,000
Actually, was it a binary classification of reviews?

613
00:29:42,000 --> 00:29:42,000
Right.

614
00:29:42,000 --> 00:29:43,000
Okay.

615
00:29:43,000 --> 00:29:49,000
So we're going to build a function around this and we're going to, so typically

616
00:29:49,000 --> 00:29:53,000
we restrict ourselves to search over specific families of functions.

617
00:29:53,000 --> 00:29:57,000
So something where we say, yeah, the function from the input to the output.

618
00:29:58,000 --> 00:29:59,000
Couldn't be anything.

619
00:29:59,000 --> 00:30:03,000
It could be something where we say, yeah, maybe just a, maybe

620
00:30:03,000 --> 00:30:05,000
just a linear function, right?

621
00:30:05,000 --> 00:30:05,000
Why not?

622
00:30:06,000 --> 00:30:12,000
So when we restrict ourselves to sort of like a class of functions, we're

623
00:30:12,000 --> 00:30:14,000
putting there some inductive bias.

624
00:30:14,000 --> 00:30:17,000
So we're saying, well, only certain solutions are important.

625
00:30:17,000 --> 00:30:18,000
Okay.

626
00:30:19,000 --> 00:30:22,000
So let's move to a high dimensional linear functions now.

627
00:30:23,000 --> 00:30:25,000
And all this is very awful slide.

628
00:30:25,000 --> 00:30:28,000
I'm sorry about it, but let's, let's go through.

629
00:30:28,000 --> 00:30:31,000
So what will be our function?

630
00:30:31,000 --> 00:30:35,000
It will be from some input dimensions to some output dimensions.

631
00:30:36,000 --> 00:30:41,000
And we're gonna, oh, we've seen this before.

632
00:30:41,000 --> 00:30:43,000
So our linear function is already what we've seen before.

633
00:30:43,000 --> 00:30:46,000
It's a vector times a matrix plus another vector.

634
00:30:47,000 --> 00:30:47,000
Okay.

635
00:30:47,000 --> 00:30:48,000
Yeah.

636
00:30:48,000 --> 00:30:50,000
So this is our linear linear function.

637
00:30:51,000 --> 00:30:57,000
So we write it as FX or here FX with the parameters, very explicit

638
00:30:57,000 --> 00:31:00,000
here, like the, the W matrix and the B vector.

639
00:31:00,000 --> 00:31:01,000
Okay.

640
00:31:01,000 --> 00:31:05,000
So this is our linear function is basically multiplying a vector by some

641
00:31:05,000 --> 00:31:11,000
matrix, which is a projection, and then adding some, something here, some, another

642
00:31:11,000 --> 00:31:13,000
vector, okay.

643
00:31:13,000 --> 00:31:13,000
Oh, good.

644
00:31:13,000 --> 00:31:14,000
Everybody's with me.

645
00:31:14,000 --> 00:31:15,000
Linear function.

646
00:31:16,000 --> 00:31:18,000
Vector times matrix plus a vector.

647
00:31:19,000 --> 00:31:19,000
It's very simple.

648
00:31:19,000 --> 00:31:23,000
It's a, it's indeed a like very simple mapping, very simple function.

649
00:31:24,000 --> 00:31:25,000
And here, so, okay.

650
00:31:25,000 --> 00:31:31,000
We call them the X is the input and the matrix W and B are the parameters.

651
00:31:31,000 --> 00:31:33,000
So we call them the parameters of this function.

652
00:31:33,000 --> 00:31:37,000
And here we have put the explicit parameters here, right?

653
00:31:37,000 --> 00:31:40,000
So we're saying, yeah, this is parameterized by V and B.

654
00:31:40,000 --> 00:31:41,000
Okay.

655
00:31:42,000 --> 00:31:47,000
So the output of this function will be something projected and little bit shifted.

656
00:31:48,000 --> 00:31:48,000
And okay.

657
00:31:48,000 --> 00:31:49,000
Back to the parameters.

658
00:31:49,000 --> 00:31:52,000
We denote them with this very ugly thing.

659
00:31:52,000 --> 00:31:54,000
So what is, what is this ugly symbol?

660
00:31:57,000 --> 00:31:59,000
Anyone recognizes this very ugly symbol here?

661
00:32:02,000 --> 00:32:03,000
It's theta.

662
00:32:03,000 --> 00:32:03,000
Yeah.

663
00:32:03,000 --> 00:32:04,000
It's theta.

664
00:32:04,000 --> 00:32:06,000
It's a big, large theta in LaTeX.

665
00:32:08,000 --> 00:32:08,000
Okay.

666
00:32:08,000 --> 00:32:09,000
So this is theta.

667
00:32:09,000 --> 00:32:12,000
It's very fancy machine learning, like parameters is theta.

668
00:32:12,000 --> 00:32:13,000
Whatever is in there.

669
00:32:13,000 --> 00:32:16,000
So our theta here, our parameters are W and B.

670
00:32:17,000 --> 00:32:19,000
And now we want to, yes, you have a question.

671
00:32:24,000 --> 00:32:27,000
What's the difference between the parameters W and B?

672
00:32:31,000 --> 00:32:33,000
What's the difference between W and B?

673
00:32:34,000 --> 00:32:38,000
Well, so they, they have different, well, they are all, both are parameters of the

674
00:32:38,000 --> 00:32:40,000
function of the linear transformation.

675
00:32:40,000 --> 00:32:45,000
Only they, the W, W is a matrix and B is a vector.

676
00:32:47,000 --> 00:32:48,000
This is the only difference.

677
00:32:48,000 --> 00:32:49,000
That's the only difference.

678
00:32:49,000 --> 00:32:51,000
It's just parameters of our function.

679
00:32:53,000 --> 00:32:54,000
I don't think so.

680
00:32:55,000 --> 00:32:55,000
I don't think so.

681
00:32:56,000 --> 00:32:57,000
So parameters means either parametric function.

682
00:32:57,000 --> 00:32:59,000
What could be another parametric function?

683
00:32:59,000 --> 00:33:02,000
Well, I don't know.

684
00:33:03,000 --> 00:33:04,000
Something which is not linear function.

685
00:33:04,000 --> 00:33:04,000
Okay.

686
00:33:04,000 --> 00:33:08,000
So, Gaussian distribution, who knows Gaussian distribution?

687
00:33:10,000 --> 00:33:13,000
So it's parameterized by mu and sigma.

688
00:33:14,000 --> 00:33:18,000
Like the mean and the standard deviation.

689
00:33:18,000 --> 00:33:20,000
These are parameters of the function, right?

690
00:33:20,000 --> 00:33:23,000
So, and then the function depends on these two parameters.

691
00:33:23,000 --> 00:33:26,000
If you write the Python function, you put parameters in there.

692
00:33:27,000 --> 00:33:28,000
There could be anything.

693
00:33:28,000 --> 00:33:30,000
One could be an array and or it could be a string, whatever.

694
00:33:30,000 --> 00:33:31,000
So it's the same thing.

695
00:33:31,000 --> 00:33:32,000
Okay.

696
00:33:34,000 --> 00:33:41,000
And the goal of learning is to find such values of W and B that our function

697
00:33:42,000 --> 00:33:46,000
is doing what it's supposed to do on a collection of input values.

698
00:33:46,000 --> 00:33:49,000
So these are the inputs and these are the outputs.

699
00:33:49,000 --> 00:33:52,000
So basically for each input, it should produce the expected output.

700
00:33:53,000 --> 00:33:53,000
Right?

701
00:33:53,000 --> 00:33:58,000
So we want the function to take text, which is positive and to spit out positive.

702
00:33:59,000 --> 00:34:00,000
That's what we want to do.

703
00:34:01,000 --> 00:34:03,000
And we're going to model this with this linear function.

704
00:34:04,000 --> 00:34:04,000
Right?

705
00:34:04,000 --> 00:34:09,000
And we want to learn such a parameters of the function that the function is doing

706
00:34:09,000 --> 00:34:12,000
or the prediction is doing what we want to do with.

707
00:34:14,000 --> 00:34:19,000
Is it clear enough so far or anyone struggles with this formalization?

708
00:34:24,000 --> 00:34:24,000
Great.

709
00:34:24,000 --> 00:34:28,000
We're going to make it much easier in the next slides because we're going

710
00:34:28,000 --> 00:34:30,000
to focus on binary classification.

711
00:34:31,000 --> 00:34:35,000
So here the input will be still some high dimensional vector, but

712
00:34:35,000 --> 00:34:38,000
the output will be a scalar.

713
00:34:39,000 --> 00:34:41,000
So it changes our function from the previous one.

714
00:34:41,000 --> 00:34:46,000
Like this W is not another matrix anymore, but it's just a vector.

715
00:34:47,000 --> 00:34:49,000
And this is what we had before again, like linear.

716
00:34:49,000 --> 00:34:53,000
So the product was some offset here.

717
00:34:54,000 --> 00:34:54,000
Okay.

718
00:34:54,000 --> 00:34:57,000
So this is our, this will be our binary classification

719
00:34:57,000 --> 00:34:59,000
linear function for today's task.

720
00:35:01,000 --> 00:35:03,000
So, but okay.

721
00:35:03,000 --> 00:35:08,000
So for binary text classification, for text classification, our input is

722
00:35:08,000 --> 00:35:10,000
in the form of nature language text.

723
00:35:11,000 --> 00:35:13,000
Where do you see nature language text here?

724
00:35:15,000 --> 00:35:17,000
I don't, I see X and this is like a vector.

725
00:35:18,000 --> 00:35:22,000
It's kind of how, what should we do?

726
00:35:22,000 --> 00:35:22,000
Okay.

727
00:35:22,000 --> 00:35:23,000
Well, this is one problem.

728
00:35:23,000 --> 00:35:27,000
The other problem is that the labels we are having positive and

729
00:35:27,000 --> 00:35:31,000
negative are two categories, but our Y, our open to the function is a scalar.

730
00:35:31,000 --> 00:35:32,000
Right?

731
00:35:32,000 --> 00:35:33,000
So what shall we do about it?

732
00:35:33,000 --> 00:35:34,000
Well, this is simple.

733
00:35:35,000 --> 00:35:39,000
This task, we're just going to say that we're going to map

734
00:35:39,000 --> 00:35:41,000
these categories into zero and one.

735
00:35:41,000 --> 00:35:44,000
So we're going to say maybe like negative will be zero and

736
00:35:44,000 --> 00:35:45,000
positive will be associated with one.

737
00:35:46,000 --> 00:35:48,000
This is our arbitrary decision.

738
00:35:48,000 --> 00:35:49,000
So it could be the way, the other way around.

739
00:35:50,000 --> 00:35:51,000
Why zero and one?

740
00:35:51,000 --> 00:35:53,000
Why, why, why should we, should zero and one?

741
00:35:55,000 --> 00:35:56,000
Any idea why is it so?

742
00:35:59,000 --> 00:36:00,000
Exactly.

743
00:36:00,000 --> 00:36:01,000
It's just this convenient.

744
00:36:01,000 --> 00:36:02,000
It's not the easiest way.

745
00:36:02,000 --> 00:36:06,000
It could be like minus one and plus one or zero and a hundred, but zero and

746
00:36:06,000 --> 00:36:08,000
one is just mathematically convenient.

747
00:36:08,000 --> 00:36:11,000
So it will be, you know, it will play out easily then in the calculations.

748
00:36:13,000 --> 00:36:15,000
So now we have to talk about the first problem, right?

749
00:36:15,000 --> 00:36:18,000
I mean, how to take nature language text and plug it into this,

750
00:36:18,000 --> 00:36:20,000
this input like vector.

751
00:36:20,000 --> 00:36:21,000
Oh, okay.

752
00:36:22,000 --> 00:36:25,000
So numerical representation of nature language text.

753
00:36:25,000 --> 00:36:26,000
It's going to be a little challenging here.

754
00:36:26,000 --> 00:36:32,000
So we need to transform text into a fixed size vector of real numbers, right?

755
00:36:32,000 --> 00:36:33,000
So this is our setup.

756
00:36:33,000 --> 00:36:33,000
This is our function.

757
00:36:34,000 --> 00:36:36,000
Vector in scalar out.

758
00:36:36,000 --> 00:36:39,000
So this is solved, but we need a vector in which is this function.

759
00:36:39,000 --> 00:36:44,000
So we need, we need this thing, but what we have is the text.

760
00:36:44,000 --> 00:36:48,000
For example, one of my favorite movies ever now here, see the typo here.

761
00:36:48,000 --> 00:36:49,000
So there's no white space.

762
00:36:50,000 --> 00:36:51,000
Jesus, people are terrible in writing.

763
00:36:51,000 --> 00:36:54,000
The chef's Shawshank Redemption is a modern day play.

764
00:36:55,000 --> 00:36:59,000
Is a modern day plastic and a blah, blah, blah, blah, blah, blah, blah, blah.

765
00:36:59,000 --> 00:37:00,000
And another like a hundred characters.

766
00:37:01,000 --> 00:37:04,000
So, I mean, they have different lengths just to begin with.

767
00:37:05,000 --> 00:37:07,000
Like one, one review is just, you know, 20 characters.

768
00:37:07,000 --> 00:37:10,000
And that is like five to 50 pages long, maybe.

769
00:37:12,000 --> 00:37:15,000
So we need to transfer it into these words.

770
00:37:15,000 --> 00:37:17,000
We need to transfer them into the, into a vector.

771
00:37:17,000 --> 00:37:18,000
How shall we do that?

772
00:37:18,000 --> 00:37:23,000
So there is one, one thing we need to talk about.

773
00:37:24,000 --> 00:37:27,000
And we need to talk about what is a word, right?

774
00:37:27,000 --> 00:37:28,000
What is a word?

775
00:37:29,000 --> 00:37:31,000
So it's a matter of debate and linguists.

776
00:37:31,000 --> 00:37:36,000
It's not always clear, but for us, so let's start with some very simplistic

777
00:37:36,000 --> 00:37:41,000
definition that words are sequences of letters separated by white space.

778
00:37:41,000 --> 00:37:42,000
Fair enough.

779
00:37:42,000 --> 00:37:47,000
So, but then this example, like dog comma dog, question mark dot

780
00:37:47,000 --> 00:37:50,000
period and dog parentheses.

781
00:37:51,000 --> 00:37:52,000
These will be different words, right?

782
00:37:52,000 --> 00:37:54,000
If you just split them by white space.

783
00:37:54,000 --> 00:37:57,000
So maybe, maybe this is not like the best definition ever.

784
00:37:58,000 --> 00:37:59,000
So then let's do better.

785
00:38:00,000 --> 00:38:04,000
Words are separated by white space or punctuations.

786
00:38:04,000 --> 00:38:05,000
Yeah, this is much better.

787
00:38:05,000 --> 00:38:09,000
So we would solve this and the process of splitting text into these

788
00:38:09,000 --> 00:38:11,000
words, it's called tokenization.

789
00:38:12,000 --> 00:38:16,000
So we split it into so-called tokens based on white spaces and punctuation.

790
00:38:17,000 --> 00:38:21,000
And the thing is like in English, the job of the tokenizer is quite simpler, right?

791
00:38:21,000 --> 00:38:24,000
So we have like words, white spaces and punctuation and you cut them

792
00:38:24,000 --> 00:38:25,000
into tokens and call it a day.

793
00:38:26,000 --> 00:38:30,000
So Hebrew and Arabic, anyone speaks Hebrew and Arabic here?

794
00:38:30,000 --> 00:38:31,000
Yeah.

795
00:38:31,000 --> 00:38:32,000
Can you split the text by white space?

796
00:38:34,000 --> 00:38:35,000
Most of the time.

797
00:38:35,000 --> 00:38:35,000
Okay.

798
00:38:35,000 --> 00:38:37,000
So this is like, so, so, oh yeah, let's see.

799
00:38:38,000 --> 00:38:39,000
So who speak Chinese here?

800
00:38:40,000 --> 00:38:43,000
Can you, can you split a text by white spaces?

801
00:38:43,000 --> 00:38:43,000
Yeah.

802
00:38:43,000 --> 00:38:46,000
So I would say like 1% of the time it will work.

803
00:38:47,000 --> 00:38:48,000
Maybe.

804
00:38:48,000 --> 00:38:49,000
So why exactly?

805
00:38:49,000 --> 00:38:52,000
So in China, I don't speak Chinese, but I kind of believe what they're saying

806
00:38:52,000 --> 00:38:53,000
that there's no white spaces in Chinese.

807
00:38:53,000 --> 00:38:54,000
So how can you split a verb?

808
00:38:54,000 --> 00:38:55,000
Yes.

809
00:38:58,000 --> 00:38:59,000
Is it?

810
00:39:01,000 --> 00:39:03,000
Is it like one character corresponds to one word?

811
00:39:05,000 --> 00:39:05,000
No.

812
00:39:06,000 --> 00:39:06,000
Yeah.

813
00:39:06,000 --> 00:39:09,000
It's like, it's like, it's like, it's like, it's like, it's like, it's like,

814
00:39:09,000 --> 00:39:12,000
it's like, it's like, it's like, it's like, it's like, it's like, it's like,

815
00:39:13,000 --> 00:39:14,000
yeah, sometimes.

816
00:39:14,000 --> 00:39:15,000
Yeah.

817
00:39:15,000 --> 00:39:16,000
Oh yeah.

818
00:39:16,000 --> 00:39:17,000
It's complicated, right?

819
00:39:17,000 --> 00:39:17,000
Okay.

820
00:39:17,000 --> 00:39:19,000
So that's why.

821
00:39:19,000 --> 00:39:19,000
Okay.

822
00:39:19,000 --> 00:39:19,000
So now, okay.

823
00:39:20,000 --> 00:39:22,000
Let's, let's forget words and come to tokens.

824
00:39:22,000 --> 00:39:23,000
Okay.

825
00:39:23,000 --> 00:39:24,000
So this is complicated, right?

826
00:39:25,000 --> 00:39:25,000
Tokens.

827
00:39:25,000 --> 00:39:32,000
Um, and then the symbols cat and capital C cat have the same meaning, but

828
00:39:32,000 --> 00:39:36,000
there are the same word, but depends or something like New York is two words or

829
00:39:36,000 --> 00:39:40,000
one, so we're going to distinguish between words and tokens.

830
00:39:41,000 --> 00:39:47,000
And the output of the tokenizer is then by definition, token and something which

831
00:39:47,000 --> 00:39:51,000
is, which has the meaning and you can find maybe in dictionary will be, will be

832
00:39:51,000 --> 00:39:56,000
words, but keep in mind that we will use these terms word very loosely and we

833
00:39:56,000 --> 00:39:58,000
will interchange with tokens, right?

834
00:39:59,000 --> 00:40:03,000
So kind of, we ignore all these tiny little details from linguistics and

835
00:40:03,000 --> 00:40:07,000
say, ah, it's a word or token or tokens mostly, but the reality, the story is

836
00:40:07,000 --> 00:40:08,000
just hard, right?

837
00:40:08,000 --> 00:40:09,000
As we just saw.

838
00:40:10,000 --> 00:40:12,000
But anyway, we want to really tokenize Chinese texts.

839
00:40:12,000 --> 00:40:14,000
We want to tokenize Arabic texts and stuff like that.

840
00:40:15,000 --> 00:40:18,000
So let's, let's start with it.

841
00:40:18,000 --> 00:40:18,000
So let's start.

842
00:40:19,000 --> 00:40:23,000
How can we, so the goal now what's what's what's the problem again?

843
00:40:23,000 --> 00:40:25,000
We want to turn text into a vector.

844
00:40:25,000 --> 00:40:25,000
Okay.

845
00:40:25,000 --> 00:40:26,000
Okay.

846
00:40:26,000 --> 00:40:27,000
So we know what the words are tokens are.

847
00:40:27,000 --> 00:40:28,000
We can tokenize text.

848
00:40:28,000 --> 00:40:29,000
This is great.

849
00:40:30,000 --> 00:40:33,000
So let's start, let's start building vocabulary.

850
00:40:34,000 --> 00:40:39,000
So we, we take a training data maybe, or some other data and we

851
00:40:39,000 --> 00:40:42,000
build a fixed sized static vocabulary.

852
00:40:43,000 --> 00:40:44,000
And how can we do that?

853
00:40:44,000 --> 00:40:46,000
Maybe by tokenizing some training data, right?

854
00:40:46,000 --> 00:40:49,000
So you're basically take your training data, which is a hundred thousand

855
00:40:49,000 --> 00:40:55,000
documents, you tokenize it, and then just take all words you found, put them

856
00:40:55,000 --> 00:40:57,000
into a set and call it the vocabulary.

857
00:40:57,000 --> 00:40:58,000
Sounds good.

858
00:40:59,000 --> 00:41:00,000
Sounds good to me.

859
00:41:00,000 --> 00:41:03,000
I mean, this is how typically things have been done or are done.

860
00:41:04,000 --> 00:41:08,000
So the typical sizes of the vocabularies are yeah.

861
00:41:08,000 --> 00:41:10,000
Roughly 20,000, a hundred thousand words.

862
00:41:10,000 --> 00:41:12,000
How many words are in the language?

863
00:41:13,000 --> 00:41:17,000
Like how many words are in, I don't know, uh, English.

864
00:41:18,000 --> 00:41:19,000
Distinct words.

865
00:41:22,000 --> 00:41:23,000
600,000.

866
00:41:23,000 --> 00:41:23,000
Yeah.

867
00:41:23,000 --> 00:41:24,000
I trust you.

868
00:41:24,000 --> 00:41:25,000
It could be like that.

869
00:41:25,000 --> 00:41:25,000
Yeah.

870
00:41:25,000 --> 00:41:31,000
It could be more in like, depending on what word is, is it a lemma or is it

871
00:41:31,000 --> 00:41:32,000
with suffixes and you know, things like that.

872
00:41:33,000 --> 00:41:37,000
If you tokenize training data, yeah, you kind of ignore all these nuances.

873
00:41:37,000 --> 00:41:41,000
And then typically you, you would pick like the most common words, like what

874
00:41:41,000 --> 00:41:43,000
are, you know, for the vocabulary, like most common words, 20 to a hundred

875
00:41:43,000 --> 00:41:48,000
thousand words, and then you basically maybe sort them, maybe not.

876
00:41:48,000 --> 00:41:49,000
So here are just alphabetically sorted.

877
00:41:50,000 --> 00:41:54,000
And this is, um, a vocabulary of the most common 3000 words in English.

878
00:41:55,000 --> 00:41:57,000
And each of them is associated with the index here.

879
00:41:57,000 --> 00:41:58,000
We're using one indexing.

880
00:41:58,000 --> 00:42:01,000
So the first, you know, at position one, we have this word

881
00:42:01,000 --> 00:42:02,000
position to the word and so on.

882
00:42:02,000 --> 00:42:03,000
So this is our vocabulary.

883
00:42:03,000 --> 00:42:07,000
We try, you know, we, we use it from, uh, from a training

884
00:42:07,000 --> 00:42:08,000
corpus by tokenizing.

885
00:42:08,000 --> 00:42:09,000
Okay.

886
00:42:09,000 --> 00:42:10,000
Any questions?

887
00:42:12,000 --> 00:42:14,000
So we need a tokenizer and then we can build a vocabulary.

888
00:42:15,000 --> 00:42:23,000
And then once we have the vocabulary, we can take the document and for each word

889
00:42:23,000 --> 00:42:30,000
in the document, we can look up a vector from this vocabulary or build a vector

890
00:42:30,000 --> 00:42:33,000
from this vocabulary and combine them together.

891
00:42:34,000 --> 00:42:35,000
So here's how it goes.

892
00:42:35,000 --> 00:42:36,000
It's called back of words.

893
00:42:37,000 --> 00:42:39,000
Let's forget about this formula first.

894
00:42:39,000 --> 00:42:40,000
Let's start with the example.

895
00:42:41,000 --> 00:42:43,000
So we have a sentence, a cat set.

896
00:42:44,000 --> 00:42:47,000
So we tokenize it into a cat and set.

897
00:42:48,000 --> 00:42:52,000
These are three tokens and we have this vocabulary, you know, 3000 words.

898
00:42:53,000 --> 00:42:55,000
And there is a, a is a position one.

899
00:42:55,000 --> 00:42:58,000
There's even cat position 852.

900
00:42:58,000 --> 00:43:00,000
And maybe there's set a position somewhere.

901
00:43:00,000 --> 00:43:03,000
I don't know, somewhere 2,179 maybe.

902
00:43:04,000 --> 00:43:10,000
So now for the word cat, sorry for the word a, the first word of the document, we're

903
00:43:10,000 --> 00:43:16,000
going to look into the position of the vocabulary where this word, where the word

904
00:43:16,000 --> 00:43:20,000
is, so a is position one, and we're going to, we're going to put a one into this

905
00:43:20,000 --> 00:43:22,000
vector and the rest will be zero.

906
00:43:22,000 --> 00:43:29,000
So it's called one hot encoding or one hot vector, because there is just one, one

907
00:43:29,000 --> 00:43:34,000
position, which is sort of hot, like on or one, and the rest is called like zeros.

908
00:43:35,000 --> 00:43:38,000
I think it's coming from some electrical engineering, maybe the term.

909
00:43:39,000 --> 00:43:40,000
Anyway, so one hot encoding.

910
00:43:40,000 --> 00:43:42,000
So then we take the second word, the cat.

911
00:43:43,000 --> 00:43:43,000
Okay.

912
00:43:44,000 --> 00:43:47,000
And find where the cat is in the vocabulary.

913
00:43:47,000 --> 00:43:54,000
So it's a position 852, which means it will be all zeros except for position one at a

914
00:43:54,000 --> 00:43:54,000
five, two.

915
00:43:55,000 --> 00:43:56,000
So there's, will be only one.

916
00:43:56,000 --> 00:44:00,000
And the same we'll do for the set, which is somewhere at another position.

917
00:44:00,000 --> 00:44:02,000
So all zeros and just one.

918
00:44:02,000 --> 00:44:03,000
Okay.

919
00:44:03,000 --> 00:44:06,000
So this is how we get one hot encoding for each of the words.

920
00:44:06,000 --> 00:44:07,000
Any questions?

921
00:44:10,000 --> 00:44:10,000
Yes.

922
00:44:12,000 --> 00:44:13,000
Say again.

923
00:44:17,000 --> 00:44:19,000
Like the size.

924
00:44:21,000 --> 00:44:21,000
Oh, no, no, no.

925
00:44:21,000 --> 00:44:23,000
The D is the length of the document.

926
00:44:23,000 --> 00:44:24,000
So this is document D.

927
00:44:24,000 --> 00:44:24,000
Okay.

928
00:44:24,000 --> 00:44:26,000
Let me just come back to the formula here.

929
00:44:26,000 --> 00:44:28,000
So we are, we are.

930
00:44:30,000 --> 00:44:34,000
Well, the, the, the formula will be clear on the next page, but here we, we are first

931
00:44:34,000 --> 00:44:36,000
looking in these, these vectors.

932
00:44:36,000 --> 00:44:39,000
So we looking for each of the word of the document.

933
00:44:39,000 --> 00:44:40,000
We iterating.

934
00:44:40,000 --> 00:44:42,000
So the I is iterating over each word.

935
00:44:42,000 --> 00:44:44,000
So here it will be one, two, three.

936
00:44:45,000 --> 00:44:48,000
And we're looking out for each of the word, the one hot vector from the

937
00:44:48,000 --> 00:44:50,000
vocabulary, does it answer your question?

938
00:44:51,000 --> 00:44:51,000
Okay.

939
00:44:51,000 --> 00:44:52,000
You have a question.

940
00:45:01,000 --> 00:45:03,000
I don't think I understood your question.

941
00:45:04,000 --> 00:45:09,000
So like, instead of writing one zero, like one, one, and two, two thousand,

942
00:45:09,000 --> 00:45:17,000
999 zeros, which I just write like zeroes and months.

943
00:45:18,000 --> 00:45:20,000
I just write these zeros and months.

944
00:45:21,000 --> 00:45:26,000
So they just recurring to like the characters, like, you know, look it up.

945
00:45:27,000 --> 00:45:28,000
Like the number.

946
00:45:28,000 --> 00:45:31,000
And then you, you have, you can just a number you would just write.

947
00:45:31,000 --> 00:45:32,000
Okay.

948
00:45:32,000 --> 00:45:32,000
Okay.

949
00:45:32,000 --> 00:45:36,000
You would say A is A is one.

950
00:45:36,000 --> 00:45:38,000
You would say, okay, so here I'm going to use different color.

951
00:45:39,000 --> 00:45:40,000
Yes.

952
00:45:40,000 --> 00:45:46,000
This would be like one, this would be like a 85, two, and this would be like a two,

953
00:45:46,000 --> 00:45:48,000
one, seven, nine, this is what you propose.

954
00:45:48,000 --> 00:45:49,000
Okay.

955
00:45:50,000 --> 00:45:54,000
This is a good idea, but the problem is that you're putting some sort of, you're

956
00:45:54,000 --> 00:46:02,000
putting this into one scale, which will make it, make it somehow ordered or

957
00:46:02,000 --> 00:46:05,000
comparable, I mean, these are discrete things.

958
00:46:05,000 --> 00:46:10,000
So there is no, their, their distance is always the same.

959
00:46:10,000 --> 00:46:11,000
There is no notion of similarity.

960
00:46:12,000 --> 00:46:16,000
While if you put them into just one scaler, you're, you're imposing some

961
00:46:16,000 --> 00:46:21,000
sort of ordering of these words or, or, you know, there may be there to call

962
00:46:21,000 --> 00:46:22,000
they're closer in this, what I mentioned.

963
00:46:23,000 --> 00:46:23,000
How do you know?

964
00:46:23,000 --> 00:46:24,000
We don't know.

965
00:46:25,000 --> 00:46:28,000
So you basically start with this one open coding, right?

966
00:46:29,000 --> 00:46:32,000
So this wouldn't really work then in the models we're trying to do,

967
00:46:33,000 --> 00:46:34,000
because these are distinct categories.

968
00:46:34,000 --> 00:46:37,000
You have to kind of put them each into one dimension.

969
00:46:37,000 --> 00:46:38,000
Yes, you have a question.

970
00:46:38,000 --> 00:46:42,000
One of the important things here is that the distance is always the same.

971
00:46:42,000 --> 00:46:43,000
Yes.

972
00:46:43,000 --> 00:46:43,000
Yes.

973
00:46:44,000 --> 00:46:45,000
So the distance, okay.

974
00:46:45,000 --> 00:46:46,000
Who knows Hemming distance?

975
00:46:48,000 --> 00:46:49,000
Well, Hemming distance.

976
00:46:49,000 --> 00:46:49,000
Okay.

977
00:46:49,000 --> 00:46:50,000
Very few.

978
00:46:50,000 --> 00:46:55,000
So Hemming distance is basically how many, if you have these two, so

979
00:46:55,000 --> 00:46:57,000
how many bits are different?

980
00:46:58,000 --> 00:46:58,000
Right.

981
00:46:59,000 --> 00:47:01,000
So what's the Hemming distance between these two words?

982
00:47:03,000 --> 00:47:03,000
Two.

983
00:47:04,000 --> 00:47:04,000
Exactly.

984
00:47:05,000 --> 00:47:06,000
What's the Hemming distance between these two words?

985
00:47:08,000 --> 00:47:09,000
Two again.

986
00:47:09,000 --> 00:47:11,000
What's the distance between these two words?

987
00:47:11,000 --> 00:47:11,000
Two.

988
00:47:12,000 --> 00:47:13,000
Right.

989
00:47:13,000 --> 00:47:15,000
So they have the same distance to each other.

990
00:47:16,000 --> 00:47:19,000
And there is no notion of similarity at all whatsoever.

991
00:47:19,000 --> 00:47:21,000
This is a feature and a bug at the same time.

992
00:47:21,000 --> 00:47:24,000
Feature because it's simple, bug because it won't work as we want.

993
00:47:24,000 --> 00:47:28,000
So we will find better solutions, but this is like the most basic thing.

994
00:47:28,000 --> 00:47:29,000
Yes.

995
00:47:29,000 --> 00:47:30,000
You just, you just proceed as usual.

996
00:47:31,000 --> 00:47:32,000
You just have multiple words.

997
00:47:32,000 --> 00:47:35,000
I'll get to this, the full back of words in the next slide.

998
00:47:36,000 --> 00:47:36,000
Yes.

999
00:47:42,000 --> 00:47:43,000
Oh, the order of words.

1000
00:47:44,000 --> 00:47:44,000
This is interesting.

1001
00:47:44,000 --> 00:47:44,000
Okay.

1002
00:47:44,000 --> 00:47:47,000
Let me come, let me go to the next slide and then we'll talk about order of words.

1003
00:47:49,000 --> 00:47:54,000
Because then the, we take the average back of words, which the first

1004
00:47:54,000 --> 00:47:59,000
Because then the, we take the average back of words, which the formula was,

1005
00:47:59,000 --> 00:48:01,000
we're kind of summing up all the vectors.

1006
00:48:01,000 --> 00:48:09,000
So here we say, okay, this would be like, so the sum will be one zero zero.

1007
00:48:09,000 --> 00:48:10,000
Then it will be one somewhere.

1008
00:48:11,000 --> 00:48:11,000
Zero zero.

1009
00:48:11,000 --> 00:48:14,000
Then we'll be one somewhere and all the zeros.

1010
00:48:14,000 --> 00:48:15,000
This will be the sum of the three vectors.

1011
00:48:15,000 --> 00:48:15,000
Right.

1012
00:48:17,000 --> 00:48:20,000
And we're just dividing by the, by the number of tokens here, which is three.

1013
00:48:20,000 --> 00:48:27,000
So here the size of the document is three, which will gives us the final.

1014
00:48:27,000 --> 00:48:32,000
One third, very many zeros, one third, very many zeros, one third, very many zeros.

1015
00:48:32,000 --> 00:48:33,000
This is the final thing.

1016
00:48:34,000 --> 00:48:36,000
And there's two things we are discussing.

1017
00:48:36,000 --> 00:48:37,000
One is the ordering of the words.

1018
00:48:37,000 --> 00:48:45,000
So what will be the difference between a cat set or a set cat?

1019
00:48:46,000 --> 00:48:49,000
This makes no sense, obviously, but what will be the difference

1020
00:48:49,000 --> 00:48:50,000
in the final representation?

1021
00:48:52,000 --> 00:48:53,000
None.

1022
00:48:53,000 --> 00:48:54,000
Yes.

1023
00:48:54,000 --> 00:48:58,000
So you basically, by this one-hot encoding or average back of words, we're just

1024
00:48:58,000 --> 00:49:02,000
throwing everything into one bag and don't care the, you know, which

1025
00:49:02,000 --> 00:49:03,000
word comes after which one.

1026
00:49:04,000 --> 00:49:04,000
Okay.

1027
00:49:05,000 --> 00:49:06,000
Is it a good thing or a bad thing?

1028
00:49:09,000 --> 00:49:09,000
It's a bad thing.

1029
00:49:09,000 --> 00:49:11,000
Well, I, I, yes, I would say yes.

1030
00:49:11,000 --> 00:49:13,000
I mean, it makes no sense linguistically.

1031
00:49:13,000 --> 00:49:18,000
Empirically, it works really well as a feature for so many classification tasks.

1032
00:49:18,000 --> 00:49:19,000
You will be surprised.

1033
00:49:20,000 --> 00:49:20,000
Okay.

1034
00:49:21,000 --> 00:49:24,000
It makes things so much easier because it's basically throwing

1035
00:49:24,000 --> 00:49:25,000
everything into the bag.

1036
00:49:25,000 --> 00:49:28,000
So then there was a question who asked like the repeating words.

1037
00:49:29,000 --> 00:49:29,000
Yes.

1038
00:49:30,000 --> 00:49:34,000
So if you had like a cat set, set, set, then you would count.

1039
00:49:35,000 --> 00:49:38,000
So this would be like the last word again, you would kind of twice.

1040
00:49:38,000 --> 00:49:41,000
And basically this will change to one, one over four, one over

1041
00:49:41,000 --> 00:49:43,000
four, one over four and one half.

1042
00:49:44,000 --> 00:49:44,000
Okay.

1043
00:49:45,000 --> 00:49:45,000
Good.

1044
00:49:46,000 --> 00:49:48,000
Any question to this?

1045
00:49:48,000 --> 00:49:48,000
Yes.

1046
00:49:49,000 --> 00:49:57,000
Can you work with PolyVersion in your future projects, not to

1047
00:49:57,000 --> 00:49:59,000
filter or, to use the olhos tool.

1048
00:49:59,000 --> 00:50:03,000
Because if you can, if you can, especially in the half block

1049
00:50:03,000 --> 00:50:07,000
of language that they need and mostly with the limited resources,

1050
00:50:07,000 --> 00:50:10,000
which is really important nowadays, when we're learning concepts

1051
00:50:10,000 --> 00:50:13,000
and things like this, and any way that you can open up different

1052
00:50:13,000 --> 00:50:18,000
tools to make completely different concepts, which is really

1053
00:50:18,000 --> 00:50:23,000
important. And then you, if New York, if New York were one token,

1054
00:50:24,000 --> 00:50:28,000
you would represent it as a 0, 0, 0, 0 position of New York, this

1055
00:50:28,000 --> 00:50:34,000
one and 0, 0, 0, 0 until the end of the vocabulary. Okay. Yes.

1056
00:50:42,000 --> 00:50:45,000
Yeah, I don't think you, I don't think you would, you would have

1057
00:50:45,000 --> 00:50:48,000
it like that. I don't think so because of the ambiguity, like

1058
00:50:48,000 --> 00:50:52,000
why? So the idea is vocabulary is basically to have the, like the

1059
00:50:52,000 --> 00:50:56,000
lowest kind of, it should be like perfect. So if you, if you go

1060
00:50:56,000 --> 00:50:58,000
from left to right by the characters, you hit the end of the

1061
00:50:58,000 --> 00:51:02,000
vocabulary of the token or the length, the longest sequence of

1062
00:51:02,000 --> 00:51:05,000
characters, which corresponds to the word in the vocabulary. It

1063
00:51:05,000 --> 00:51:12,000
shouldn't make sense like that. Okay, good. Yes. Yeah, absolutely.

1064
00:51:12,000 --> 00:51:14,000
The method has proven to everything, which has something to

1065
00:51:14,000 --> 00:51:19,000
do with linguistics, like negations. Of course I was happy.

1066
00:51:19,000 --> 00:51:24,000
I was not happy. Well, not, I know how would you like, you can

1067
00:51:24,000 --> 00:51:27,000
make an example where the ordering really makes a huge

1068
00:51:27,000 --> 00:51:31,000
difference. Obviously. Yeah. Negation is one of them. The

1069
00:51:31,000 --> 00:51:34,000
movie was good. The movie was not good. You throw it into one

1070
00:51:34,000 --> 00:51:39,000
and then yeah. Well, what's yeah. Not good or good. Yes.

1071
00:51:39,000 --> 00:51:46,000
But second misspelled words. Well, misspelled words is like

1072
00:51:46,000 --> 00:51:51,000
how we build your vocabulary. So yeah. So, you know, misspellings

1073
00:51:51,000 --> 00:51:53,000
is like, you have the same word twice in the vocabulary. One,

1074
00:51:53,000 --> 00:51:57,000
one's is misspelled and one is one is correct. This is a

1075
00:51:57,000 --> 00:51:58,000
trouble you first, you second.

1076
00:51:58,000 --> 00:52:01,000
Yeah. Yeah. Okay. Yeah. That's a, that's a good example. Exactly.

1077
00:52:01,000 --> 00:52:03,000
Yes. Okay. You are second.

1078
00:52:04,000 --> 00:52:07,000
It's imaginable that there are tokens that won't be in the

1079
00:52:07,000 --> 00:52:13,000
vector so that we leave out words that are missing.

1080
00:52:15,000 --> 00:52:16,000
Exactly.

1081
00:52:17,000 --> 00:52:19,000
So I didn't look it up. Okay, good. Good for you. Good for

1082
00:52:19,000 --> 00:52:23,000
you. Don't look it up. Don't spoil it. So there's words in

1083
00:52:23,000 --> 00:52:26,000
language that are so okay. Words in language are unevenly

1084
00:52:26,000 --> 00:52:29,000
distributed. There's a things called zip slow, which somehow

1085
00:52:29,000 --> 00:52:31,000
says like there's exponential decay in the distribution of

1086
00:52:31,000 --> 00:52:36,000
the common words. So most there is a lot of words that are

1087
00:52:36,000 --> 00:52:39,000
missing. So there's a lot of words that are not even

1088
00:52:39,000 --> 00:52:41,000
distributed. So there's a lot of words that are not even

1089
00:52:41,000 --> 00:52:44,000
distributed. So there's a lot of words that are not even

1090
00:52:44,000 --> 00:52:48,000
so most there is a large sort of tail of the distribution of

1091
00:52:48,000 --> 00:52:50,000
rare words. So most words are somehow at beginning, they're

1092
00:52:50,000 --> 00:52:54,000
mostly used and there's just words that are rare. And there

1093
00:52:54,000 --> 00:52:58,000
are a few kind of just used very rarely, but they're there.

1094
00:52:58,000 --> 00:53:02,000
So this is the long tail of distribution. Okay. So as I

1095
00:53:02,000 --> 00:53:04,000
said before, when building the vocabulary, we use the most

1096
00:53:04,000 --> 00:53:08,000
frequent words and all others represented by an sort of like

1097
00:53:08,000 --> 00:53:14,000
unknown, unknown token. So we use you and K or maybe OOV,

1098
00:53:14,000 --> 00:53:17,000
which is out of vocabulary. So here are example of the most

1099
00:53:17,000 --> 00:53:20,000
common 3000 words, we would kind of extend the vocabulary

1100
00:53:20,000 --> 00:53:24,000
with this extra token, you and K would we maybe at the end or

1101
00:53:24,000 --> 00:53:27,000
maybe at the beginning doesn't matter. Right. So we just say

1102
00:53:27,000 --> 00:53:31,000
we have an unknown token in the vocabulary. And now it means

1103
00:53:31,000 --> 00:53:36,000
if you're trying to do one encoding and you find a word.

1104
00:53:37,000 --> 00:53:40,000
So you tokenize a text and there's a word, which is not in

1105
00:53:40,000 --> 00:53:43,000
your vocabulary, you're going to say, well, it's an unknown

1106
00:53:43,000 --> 00:53:46,000
word. So you're going to use the vector for the unknown. Okay.

1107
00:53:47,000 --> 00:53:50,000
Does it make sense? Yes.

1108
00:54:06,000 --> 00:54:14,000
Right. Yeah. Yes. Maybe. Yes.

1109
00:54:14,000 --> 00:54:17,000
Yes.

1110
00:54:31,000 --> 00:54:37,000
Good. No, no, no. I mean, it's really cool because it makes you

1111
00:54:37,000 --> 00:54:39,000
think like what, how to solve it. And this is exactly what

1112
00:54:39,000 --> 00:54:43,000
people are doing. Yeah. This is, this is really cool. Yeah. I

1113
00:54:43,000 --> 00:54:47,000
like it. Yeah. So if you don't, yeah. So, okay. Exactly. So in

1114
00:54:47,000 --> 00:54:49,000
the unknown, back to the problem, and then we'll get to

1115
00:54:49,000 --> 00:54:52,000
the solution. The problem is like a machine translation. So

1116
00:54:52,000 --> 00:54:55,000
we translate from a sequence of words into another sequence of

1117
00:54:55,000 --> 00:54:58,000
word. And if your input sequence of words, you find like

1118
00:54:58,000 --> 00:55:06,000
unknown word, how do you translate it? Like I, so tell me

1119
00:55:06,000 --> 00:55:09,000
what's your name? Luis. Okay. What's your surname?

1120
00:55:09,000 --> 00:55:17,000
Mulle. Mulle? Sorry, man. Mulle. Mulle. Okay. Mulle. Very

1121
00:55:17,000 --> 00:55:19,000
nice. Because this is, this word is not in my dictionary.

1122
00:55:22,000 --> 00:55:26,000
I know Mulle, but it doesn't, it's not a match. So it's Mulle.

1123
00:55:26,000 --> 00:55:29,000
And I would say, oh, good morning, Mr. Mulle. I want to

1124
00:55:29,000 --> 00:55:33,000
translate it to, sorry. Yeah, exactly. And I want to

1125
00:55:33,000 --> 00:55:37,000
translate it from, from English to German. But I'm parsing the

1126
00:55:37,000 --> 00:55:43,000
input sentence. Good afternoon, Mr. Mulle. I would take it good

1127
00:55:43,000 --> 00:55:47,000
afternoon, Mr. Unknown, because the word doesn't exist in my

1128
00:55:47,000 --> 00:55:50,000
vocabulary. Okay. So what I'm going to do, I'm going to, I'm

1129
00:55:50,000 --> 00:55:57,000
going to translate into, uh, uh, uh, uh, uh, uh, uh, uh, uh, uh,

1130
00:55:57,000 --> 00:56:00,000
yeah, it's bad. So what I, what I can do is like to take these

1131
00:56:00,000 --> 00:56:04,000
unknown words and just copy paste to the output. It works

1132
00:56:04,000 --> 00:56:06,000
most of the time for names, places and stuff like that, but

1133
00:56:06,000 --> 00:56:12,000
maybe there's a better way. Okay. So let's, let's go into

1134
00:56:12,000 --> 00:56:17,000
subword units, right? So we're going to use the thing called

1135
00:56:17,000 --> 00:56:22,000
byte pair encoding, and there's a procedure and how to build

1136
00:56:22,000 --> 00:56:27,000
your vocabulary from, from the smallest units ever. And I guess

1137
00:56:27,000 --> 00:56:31,000
it goes really along the lines you proposed. So let's take the

1138
00:56:31,000 --> 00:56:35,000
words in the corpus and split into characters and we can take

1139
00:56:35,000 --> 00:56:38,000
the original space with a special space character, right?

1140
00:56:38,000 --> 00:56:42,000
So we basically split everything into characters and this will be

1141
00:56:42,000 --> 00:56:46,000
our initial vocabulary. So we have vocabulary only by

1142
00:56:46,000 --> 00:56:51,000
characters, no words. Then we'll find the most frequent pair of

1143
00:56:51,000 --> 00:56:57,000
characters and merge it and put it to the vocabulary. So we're

1144
00:56:57,000 --> 00:56:59,000
fine. What's the most common pair of tokens, sorry,

1145
00:56:59,000 --> 00:57:05,000
characters and merge it and take these bigram of characters

1146
00:57:05,000 --> 00:57:08,000
and add it to the vocabulary. And then we're going to repeat

1147
00:57:09,000 --> 00:57:12,000
this for a very many number of times. We're going to be

1148
00:57:12,000 --> 00:57:16,000
merging the most common things after always updating the

1149
00:57:16,000 --> 00:57:19,000
vocabulary. And each of these steps will increase the

1150
00:57:19,000 --> 00:57:23,000
vocabulary by one thing and, you know, beyond the original

1151
00:57:23,000 --> 00:57:27,000
inventory of single characters. So we're building from subword

1152
00:57:27,000 --> 00:57:29,000
units and basically growing the words. I'll show you an example

1153
00:57:29,000 --> 00:57:33,000
and it will become much clearer how it works. When this is done

1154
00:57:33,000 --> 00:57:36,000
over large corpora and maybe then with multiple languages as

1155
00:57:36,000 --> 00:57:41,000
well, so maybe, you know, all the Wikipedia languages, the

1156
00:57:41,000 --> 00:57:44,000
byte pair encoding actually will help you prevent auto

1157
00:57:44,000 --> 00:57:48,000
vocabulary or OOV quite a lot. It's very helpful for machine

1158
00:57:48,000 --> 00:57:50,000
translation. Why is it so? So let me show an example.

1159
00:57:51,000 --> 00:57:55,000
On a toy corpus. So we have a toy corpus. It was like this fat

1160
00:57:55,000 --> 00:57:59,000
cat with the head is in the cave of the thin bat. And we split

1161
00:57:59,000 --> 00:58:03,000
it by characters and this is the white space, right? We use this

1162
00:58:03,000 --> 00:58:07,000
underscore for white spaces. So this is the first step. And now

1163
00:58:07,000 --> 00:58:11,000
we put all the characters to our vocabulary. So D H I S and so

1164
00:58:11,000 --> 00:58:17,000
on. And now we find the most common, most frequent, um,

1165
00:58:17,000 --> 00:58:21,000
bigram of characters, which is the T H. So right? T H here,

1166
00:58:21,000 --> 00:58:30,000
one, two, three, four, five, six. And we're going to merge

1167
00:58:30,000 --> 00:58:36,000
them into a single token. So we add T H to the vocabulary.

1168
00:58:37,000 --> 00:58:39,000
And now using this new one, we're going to merge them and

1169
00:58:39,000 --> 00:58:42,000
done. You basically repeat the same thing. So what is now the

1170
00:58:42,000 --> 00:58:47,000
most frequent bigram you see here? We have DHS one, one unit,

1171
00:58:47,000 --> 00:58:52,000
one token. Okay. So we're going to find, Oh, maybe a N T is four

1172
00:58:52,000 --> 00:58:56,000
times here. So the most common thing is a N T and we're going

1173
00:58:56,000 --> 00:58:59,000
to merge them again into the single token and put them into

1174
00:58:59,000 --> 00:59:04,000
the vocabulary. So here you see, we merge 80 here, 80 year,

1175
00:59:05,000 --> 00:59:09,000
uh, 80 year. And there's one more, which I can't find.

1176
00:59:11,000 --> 00:59:17,000
What? Yeah. Thanks. Four times. And let's go again. Okay. So

1177
00:59:17,000 --> 00:59:21,000
here in the next one. So this is the previous example. Now,

1178
00:59:21,000 --> 00:59:27,000
Oh, the most frequent bigram is now D H E. So, which is a year

1179
00:59:28,000 --> 00:59:34,000
and year and year. And we're going to merge them and add this

1180
00:59:34,000 --> 00:59:38,000
to the vocabulary. And okay. This is the next step. So we are

1181
00:59:38,000 --> 00:59:44,000
at the word already. You see, we are basically coming to very

1182
00:59:44,000 --> 00:59:49,000
frequent words based from single characters. So we're building

1183
00:59:49,000 --> 00:59:52,000
the vocabulary really from scratch. So after this process,

1184
00:59:52,000 --> 00:59:58,000
we have in the vocabulary, all these characters, right up until

1185
00:59:58,000 --> 01:00:02,000
here, then these bigrams, but then actual words starting to

1186
01:00:02,000 --> 01:00:05,000
emerge because they're very common. Yes. We have a question.

1187
01:00:08,000 --> 01:00:14,000
Exactly. Uh, when you, okay. I didn't put it there. Um, when

1188
01:00:14,000 --> 01:00:18,000
you, when you hit your, uh, size of the byte pair encoding. So

1189
01:00:18,000 --> 01:00:21,000
you would say I want typically 50,000 maybe or a hundred

1190
01:00:21,000 --> 01:00:25,000
thousand, similarly to, to the vocabulary, but now you have all

1191
01:00:25,000 --> 01:00:29,000
the subword in it's in there. Okay. And every question. Yes.

1192
01:00:35,000 --> 01:00:38,000
No, no, you keep it everything there because it happened as a

1193
01:00:38,000 --> 01:00:41,000
bigram in the training data. So you keep everything and you just

1194
01:00:41,000 --> 01:00:44,000
grow to birds, which are very common and you, and you, you

1195
01:00:44,000 --> 01:00:47,000
end up with birds. Any other questions? You had, you had a

1196
01:00:47,000 --> 01:00:54,000
question. Uh-huh.

1197
01:01:06,000 --> 01:01:08,000
Exactly. Yes, exactly.

1198
01:01:09,000 --> 01:01:13,000
Maybe. Yes. Yeah. You say like, well, I want a BP by 50,000,

1199
01:01:13,000 --> 01:01:18,000
maybe units. And then you start basically this process first,

1200
01:01:18,000 --> 01:01:19,000
second, third.

1201
01:01:26,000 --> 01:01:29,000
Yes. I mean, this is like, yeah, you don't care after, after you

1202
01:01:29,000 --> 01:01:32,000
finish this, this vocabulary, this by pair by pair subword to

1203
01:01:32,000 --> 01:01:34,000
vocabulary, you just, you don't need a subword. You just, you

1204
01:01:34,000 --> 01:01:36,000
just, you just, you just, you just, you just, you just, you

1205
01:01:37,000 --> 01:01:40,000
just, you don't need a text. It's just for learning. You are,

1206
01:01:40,000 --> 01:01:43,000
you had a question.

1207
01:01:53,000 --> 01:01:56,000
It might be even like whole sentences, but it's, it won't be

1208
01:01:56,000 --> 01:01:59,000
the case empirically. It could be like you grow that longer

1209
01:01:59,000 --> 01:02:04,000
over tokens that, that you will, you will end up with maybe like

1210
01:02:04,000 --> 01:02:08,000
longer sentences, but it's, it's not the case actually. So it's

1211
01:02:08,000 --> 01:02:10,000
not really the case. Maybe, maybe because you just tokenize

1212
01:02:10,000 --> 01:02:13,000
before and ignore the whitespace. I'm not sure.

1213
01:02:16,000 --> 01:02:18,000
That's, that's correct. Yeah, that's correct. I think byte

1214
01:02:18,000 --> 01:02:20,000
pair. I'm not sure. I have to, I have to double check. I don't,

1215
01:02:20,000 --> 01:02:24,000
I don't know whether by per needs pre-tokenized text. Yeah.

1216
01:02:24,000 --> 01:02:26,000
Sorry. You had somewhere in the back and then you

1217
01:02:30,000 --> 01:02:32,000
inefficient. Why?

1218
01:02:34,000 --> 01:02:46,000
What do you mean by a lot of space? You mean like the back

1219
01:02:46,000 --> 01:02:49,000
of words is inefficient because you have like a large vectors?

1220
01:02:51,000 --> 01:02:57,000
Yeah, that's correct. But what is large? Yeah. So sure. I mean,

1221
01:02:57,000 --> 01:03:00,000
a hundred thousand dimensions input vector. How large is the,

1222
01:03:00,000 --> 01:03:06,000
okay. Computer vision, image pixels, MNIST. How large is the

1223
01:03:06,000 --> 01:03:13,000
vector? 70, 80 something times 70, 80 something. So 16,000

1224
01:03:13,000 --> 01:03:19,000
bits or not bits, 16,000 pixels. And it's small. So it's

1225
01:03:19,000 --> 01:03:24,000
relative. So times three. Yeah. Okay. All the RPG. You had a

1226
01:03:24,000 --> 01:03:31,000
question. Yes. But yeah, yeah, that's fine. That maybe you don't,

1227
01:03:31,000 --> 01:03:34,000
maybe you don't need it. I mean, yeah, you don't actually need

1228
01:03:34,000 --> 01:03:35,000
it. Yes. You have a question.

1229
01:03:49,000 --> 01:03:50,000
Yes.

1230
01:03:55,000 --> 01:03:55,000
Whatever.

1231
01:03:59,000 --> 01:04:02,000
Right. Yes. It's possible that you split up words that are kind

1232
01:04:02,000 --> 01:04:05,000
of, you know, that happen, you know, that are often you might

1233
01:04:06,000 --> 01:04:09,000
end, you know, ending up splitting them. That's the,

1234
01:04:09,000 --> 01:04:13,000
that's the risk. That's true. But you can make it bigger. Let

1235
01:04:13,000 --> 01:04:18,000
me show you an example. Okay. Like a real. So here is the

1236
01:04:18,000 --> 01:04:23,000
byte per example train on. So this is like 49,500 steps of

1237
01:04:23,000 --> 01:04:27,000
BPE. And this is how you split a sentence using BPE, the

1238
01:04:27,000 --> 01:04:31,000
relationship between Obama and, and here the word was Netanyahu,

1239
01:04:32,000 --> 01:04:37,000
which wasn't apparently in the training data for BPE. But it

1240
01:04:37,000 --> 01:04:40,000
learned how to split it even like a little bit like it makes

1241
01:04:40,000 --> 01:04:43,000
a morphological sense after syllables. And then the worst,

1242
01:04:43,000 --> 01:04:47,000
the rest are just, you know, words and punctuation, which is

1243
01:04:47,000 --> 01:04:48,000
in the, in the vocabulary again.

1244
01:04:54,000 --> 01:04:54,000
Might be split up.

1245
01:04:56,000 --> 01:05:01,000
Yes. Yeah. Yeah. Yes. Yes. Yes. But it would be the same thing

1246
01:05:01,000 --> 01:05:04,000
if you take like, if you take 50,000 words, like just

1247
01:05:04,000 --> 01:05:07,000
tokenized words and sort them, you will be surprised what's in

1248
01:05:07,000 --> 01:05:10,000
there. Like very weird words, because how many words you use

1249
01:05:10,000 --> 01:05:16,000
per day, like different words, 200, 300. So 50,000 is a lot

1250
01:05:16,000 --> 01:05:20,000
actually like 50,000 words in language. If you know, you know,

1251
01:05:20,000 --> 01:05:23,000
like learning 50,000 different words in language is quite

1252
01:05:23,000 --> 01:05:27,000
a lot. It's, it's really, it's a huge, like, it's like long

1253
01:05:27,000 --> 01:05:31,000
tail, very rare words. But the advantage of that is that you

1254
01:05:31,000 --> 01:05:36,000
split words that kind of you can translate them easily. And if

1255
01:05:36,000 --> 01:05:41,000
you know, it's, yeah. Any other question? Yes, you.

1256
01:05:42,000 --> 01:05:45,000
So if I understand this correctly, it's more about

1257
01:05:45,000 --> 01:05:49,000
like tokenization? And there's still new font-type encodings?

1258
01:05:50,000 --> 01:05:52,000
Yeah, well, because we are talking about like, you know,

1259
01:05:52,000 --> 01:05:55,000
token tokens, and you said, yeah, well, everything is

1260
01:05:55,000 --> 01:05:57,000
tokenized, split by words. No, actually, I mean, you need to

1261
01:05:57,000 --> 01:06:00,000
really, if you do something later on with, you know, we'll

1262
01:06:00,000 --> 01:06:04,000
see models like BERT and transformers that use sort of

1263
01:06:05,000 --> 01:06:08,000
input tokens, but these are subword units. And it's

1264
01:06:08,000 --> 01:06:10,000
important that you know, to take it into account, because you

1265
01:06:10,000 --> 01:06:13,000
can use these subword units as the input for the linear

1266
01:06:13,000 --> 01:06:16,000
function as well. You can use just very simple unknown words

1267
01:06:16,000 --> 01:06:18,000
as well. So this is just a different flavor how to

1268
01:06:18,000 --> 01:06:23,000
transfer text, which is a stream of characters into

1269
01:06:23,000 --> 01:06:28,000
distinct units, which are tokens. Okay. Another one here

1270
01:06:28,000 --> 01:06:31,000
is the so a variant of byte pair encoding is sentence piece

1271
01:06:31,000 --> 01:06:35,000
encoding, sentence piece, encoding, sentence piece

1272
01:06:35,000 --> 01:06:40,000
tokenizer. And it works like it takes actually the whitespace

1273
01:06:40,000 --> 01:06:44,000
also into account, which would maybe help us with the New York

1274
01:06:44,000 --> 01:06:47,000
thing, I guess sentence piece would kind of take a New York as

1275
01:06:47,000 --> 01:06:52,000
one as one token, very likely. So it adds here the underscore

1276
01:06:52,000 --> 01:06:58,000
for the for the white space, and then builds the you know, the

1277
01:06:58,000 --> 01:07:01,000
same iterative process. And then the splitting would be basically

1278
01:07:01,000 --> 01:07:04,000
non that's non destructive. So it's like lossless

1279
01:07:04,000 --> 01:07:07,000
tokenization. Because here you can reproduce this back to the

1280
01:07:07,000 --> 01:07:10,000
text. Here, there was some tokenization before and you

1281
01:07:10,000 --> 01:07:15,000
know, it's a it's not maybe one to one because between these two

1282
01:07:15,000 --> 01:07:18,000
words, well, there was probably a whitespace. But here, yeah,

1283
01:07:18,000 --> 01:07:21,000
who knows, it shouldn't be any whitespace with sentence piece.

1284
01:07:22,000 --> 01:07:24,000
You have the whitespace very explicitly here. So it's a

1285
01:07:24,000 --> 01:07:27,000
different variant. It's very popular one. So if there's

1286
01:07:27,000 --> 01:07:30,000
tokenization, you should know sentence piece tokenization.

1287
01:07:30,000 --> 01:07:34,000
Okay. Any other questions tokenization? Now we kind of

1288
01:07:34,000 --> 01:07:36,000
take a, you know, tangent a little bit, but it's I think

1289
01:07:36,000 --> 01:07:38,000
it's really important to know that's just if you cut into

1290
01:07:38,000 --> 01:07:39,000
words, yes.

1291
01:07:45,000 --> 01:07:49,000
How do you how do you do exactly the tokenization when you if

1292
01:07:49,000 --> 01:07:53,000
you have the sentence piece, vocabulary, for example, you

1293
01:07:53,000 --> 01:07:59,000
start looking into the longest sequence of characters which

1294
01:07:59,000 --> 01:08:03,000
are in your in your sentence piece. And in the worst case,

1295
01:08:03,000 --> 01:08:06,000
what would be like worst case if you have, if you don't have

1296
01:08:06,000 --> 01:08:09,000
the word in your sentence piece vocabulary, what would be the

1297
01:08:09,000 --> 01:08:11,000
worst case of splitting the text?

1298
01:08:12,000 --> 01:08:14,000
Single characters, exactly. Because we have the single

1299
01:08:14,000 --> 01:08:17,000
characters, we started with the single characters. So even like

1300
01:08:17,000 --> 01:08:21,000
the super weird words, you can tokenize into characters, it

1301
01:08:21,000 --> 01:08:23,000
will be hard time then for the models to learn something

1302
01:08:23,000 --> 01:08:27,000
meaningful, but who cares? So there is nothing lost.

1303
01:08:38,000 --> 01:08:42,000
Like this up here. This is typical to this. This is how is

1304
01:08:42,000 --> 01:08:44,000
byte pair pericoding implemented in the original

1305
01:08:44,000 --> 01:08:49,000
paper. So you would add these two special characters. These

1306
01:08:49,000 --> 01:08:52,000
are the word splits. So when you split a word, you add these

1307
01:08:52,000 --> 01:08:55,000
two ampersands here at the end, because Netanyahu is one word,

1308
01:08:55,000 --> 01:08:58,000
and you split it into three tokens. And you say you signal

1309
01:08:58,000 --> 01:09:01,000
here by this that you're splitting basically the word

1310
01:09:01,000 --> 01:09:03,000
into sub subword units.

1311
01:09:07,000 --> 01:09:10,000
Sentence piece works differently, because it it

1312
01:09:10,000 --> 01:09:16,000
doesn't have these, these ugly ampersand characters. It just

1313
01:09:16,000 --> 01:09:19,000
takes even like whitespace at the same time, you know, just

1314
01:09:19,000 --> 01:09:22,000
put special characters, there's no tokenization before in

1315
01:09:22,000 --> 01:09:25,000
sentence piece. And it's learning basically just from the

1316
01:09:25,000 --> 01:09:28,000
characters for the byte pair, we just we've we had to tokenize

1317
01:09:28,000 --> 01:09:34,000
it first by whitespace. So there is subtle differences. I can I

1318
01:09:34,000 --> 01:09:36,000
would I would suggest you to read this paper like sentence

1319
01:09:36,000 --> 01:09:39,000
this this one, this is there's very clear example how this

1320
01:09:39,000 --> 01:09:41,000
works and what's the difference? Okay, you have a

1321
01:09:41,000 --> 01:09:41,000
question.

1322
01:09:42,000 --> 01:09:49,000
So the two options are do this like or or just take the

1323
01:09:49,000 --> 01:09:54,000
whitespaces and everything like consider a token everything

1324
01:09:54,000 --> 01:09:58,000
that's converged by whitespace. Right? If I don't see the

1325
01:09:58,000 --> 01:10:02,000
advantage of this alternative.

1326
01:10:03,000 --> 01:10:06,000
Yeah, okay. So you don't see why this should be better than than

1327
01:10:06,000 --> 01:10:09,000
something else like the token, because here you don't have the

1328
01:10:09,000 --> 01:10:12,000
unknown problem. You don't you don't have like, you don't have

1329
01:10:12,000 --> 01:10:14,000
unknown, you don't have all the everything will be represented.

1330
01:10:15,000 --> 01:10:20,000
But I'm going to take a lot of no words and the word word. I

1331
01:10:20,000 --> 01:10:25,000
don't want to split it into space. Okay, I'm going to lose

1332
01:10:25,000 --> 01:10:25,000
more than win.

1333
01:10:29,000 --> 01:10:31,000
Yeah, well, in the simple example of this one of the

1334
01:10:31,000 --> 01:10:34,000
encoding, there's no really, I don't think there's like super

1335
01:10:34,000 --> 01:10:37,000
advantage of using, you know, sentence piece, and sentence

1336
01:10:37,000 --> 01:10:43,000
piece, tokens that I'm on their side, but then later on for, for

1337
01:10:43,000 --> 01:10:46,000
machine translation, for example, and using transformers,

1338
01:10:46,000 --> 01:10:49,000
the input will be much better, because there is some

1339
01:10:49,000 --> 01:10:52,000
compositional of these words which are split it, and you can

1340
01:10:52,000 --> 01:10:55,000
translate, you can learn something about translation of

1341
01:10:55,000 --> 01:10:57,000
these pieces as well, even though it's not in your training

1342
01:10:57,000 --> 01:11:01,000
vocabulary. That's, that's the point, like, it's shaky

1343
01:11:01,000 --> 01:11:06,000
explanation now. But believe me, this is this is helpful for

1344
01:11:06,000 --> 01:11:09,000
machine translation quite a lot. And then it has been adopted to

1345
01:11:09,000 --> 01:11:12,000
everything. Like sentence pieces, now the tokenization for

1346
01:11:12,000 --> 01:11:15,000
everything you do with transformers for a reason. Okay.

1347
01:11:17,000 --> 01:11:23,000
Good. So tokenization vocabulary, it's covered

1348
01:11:23,000 --> 01:11:28,000
every everybody's with me. Good. So what are you trying to do?

1349
01:11:28,000 --> 01:11:32,000
Okay, we okay, we had to transform text into fixed size

1350
01:11:32,000 --> 01:11:37,000
vector of real numbers. So we made it. We have now the back of

1351
01:11:37,000 --> 01:11:41,000
words tokenized. The tokens could be really like words,

1352
01:11:41,000 --> 01:11:45,000
whitespace, or it could be subword units, fine. And the

1353
01:11:45,000 --> 01:11:49,000
dimension is in is the size of the vocabulary, right? So it's

1354
01:11:49,000 --> 01:11:53,000
some people consider it huge, like 50,000 vector, but this is

1355
01:11:53,000 --> 01:11:57,000
this is fine. Okay, so I'm thinking what to do next.

1356
01:11:59,000 --> 01:12:04,000
Because I don't think we'll cover everything I tried to

1357
01:12:04,000 --> 01:12:08,000
cover today. But let me give a shot. Like in the next 15

1358
01:12:08,000 --> 01:12:14,000
minutes. So the goal, okay, binary text classification. So

1359
01:12:14,000 --> 01:12:20,000
movies, right? We want to what do we have, we have this

1360
01:12:20,000 --> 01:12:24,000
function. Okay, we know how to convert text into a vector. This

1361
01:12:24,000 --> 01:12:27,000
is great. We have this linear function. What was that it was

1362
01:12:27,000 --> 01:12:30,000
this. This is our linear function. So we're gonna

1363
01:12:31,000 --> 01:12:34,000
multiply the input by some matrix and some something else.

1364
01:12:35,000 --> 01:12:38,000
And the output will be a scalar, which is 01. Right? So

1365
01:12:38,000 --> 01:12:41,000
everybody's with me on that. Okay, cool. This is what we

1366
01:12:41,000 --> 01:12:45,000
wanted. So we have this linear function. And now, coming back

1367
01:12:45,000 --> 01:12:49,000
to lecture two, we're going to pack everything together. And

1368
01:12:49,000 --> 01:12:52,000
what we say, like, what's the only thing, every function we're

1369
01:12:52,000 --> 01:12:56,000
working with, when we want to try to minimize something is

1370
01:12:56,000 --> 01:13:00,000
that we need the derivatives, like every function has to be

1371
01:13:00,000 --> 01:13:05,000
differentiable. So what is what is derivatives of this function,

1372
01:13:05,000 --> 01:13:07,000
this linear function with respect to the parameters, so

1373
01:13:07,000 --> 01:13:12,000
the parameters are W and B. And this is super simple, actually,

1374
01:13:12,000 --> 01:13:15,000
this is our beautiful derivatives. So the partial

1375
01:13:15,000 --> 01:13:19,000
derivative of this function with respect to any of the parameters

1376
01:13:19,000 --> 01:13:25,000
is just, why is it so? Because the partial derivatives of this

1377
01:13:25,000 --> 01:13:30,000
with respect to W1, you treat this x1 as constant, so this

1378
01:13:30,000 --> 01:13:33,000
will be x1 and the rest will be constant, which is zero. Okay?

1379
01:13:35,000 --> 01:13:38,000
Does it make sense how we do these derivatives of this

1380
01:13:38,000 --> 01:13:41,000
linear function? If not, look it up from last time, or just look

1381
01:13:41,000 --> 01:13:45,000
up how to do the differential derivatives of multivariate

1382
01:13:45,000 --> 01:13:49,000
functions, and you'll find it easy. The same with what's

1383
01:13:49,000 --> 01:13:53,000
derivatives with respect to B. So everything else is zero and

1384
01:13:53,000 --> 01:13:58,000
B will be just one. Okay, so we can differentiate this function,

1385
01:13:58,000 --> 01:14:01,000
this is great, it will be helpful later. I mean, maybe not

1386
01:14:01,000 --> 01:14:03,000
clear now why, but we have a function which is a linear

1387
01:14:03,000 --> 01:14:09,000
function, a mapping from a vector of back of words into a

1388
01:14:09,000 --> 01:14:14,000
number, and we can differentiate it. Okay, cool. Now, the point

1389
01:14:14,000 --> 01:14:19,000
is, so we have this function, right? So this is our function,

1390
01:14:19,000 --> 01:14:22,000
linear function mapping, and the range of the function is

1391
01:14:22,000 --> 01:14:27,000
unbounded. What does it mean? Well, what comes out could be

1392
01:14:27,000 --> 01:14:34,000
anything from infinity to minus infinity, right? I mean, this

1393
01:14:34,000 --> 01:14:39,000
could be anything. But the problem is, each example label

1394
01:14:39,000 --> 01:14:43,000
was either zero or one. I mean, this was our design decision, we

1395
01:14:43,000 --> 01:14:45,000
said like, oh, let's put it, negative will be zero and

1396
01:14:45,000 --> 01:14:50,000
positive will be one. So there's just one and zero. The point is,

1397
01:14:50,000 --> 01:14:55,000
well, how to reconcile this? How to make this somehow

1398
01:14:55,000 --> 01:14:59,000
compatible? Because we want our function to predict something

1399
01:14:59,000 --> 01:15:01,000
which is either zero or one, but now it's predicting something

1400
01:15:01,000 --> 01:15:05,000
from between minus infinity to plus infinity. So it's unbounded.

1401
01:15:05,000 --> 01:15:10,000
What can we do about it? Okay, you first, you second.

1402
01:15:11,000 --> 01:15:15,000
You can define some thresholds, they can decide on this certain

1403
01:15:15,000 --> 01:15:17,000
threshold value that's zero.

1404
01:15:17,000 --> 01:15:20,000
Oh, you, okay, you can say it's threshold and if the threshold

1405
01:15:20,000 --> 01:15:23,000
is over, then you would say it's one, it's a zero. It's actually

1406
01:15:23,000 --> 01:15:26,000
a very clever idea. You can maybe take like, if it's

1407
01:15:26,000 --> 01:15:28,000
positive, it will be one, if it's negative, it will be zero.

1408
01:15:28,000 --> 01:15:33,000
Okay, yeah, that's possible. And I think it's actually, if you do

1409
01:15:33,000 --> 01:15:37,000
it like that, you'll end up with a preceptron. So yeah, it's very

1410
01:15:37,000 --> 01:15:43,000
clever. And same. Okay, good. Yeah, you can, you can do some

1411
01:15:43,000 --> 01:15:46,000
thresholding functions saying, what's the problem with the

1412
01:15:46,000 --> 01:15:49,000
thresholding function? It's under, there's no problem,

1413
01:15:49,000 --> 01:15:50,000
actually, it's fine.

1414
01:15:53,000 --> 01:15:56,000
Yeah, define the threshold. Yes. Okay, yeah. But if you can say,

1415
01:15:56,000 --> 01:15:59,000
well, it's gonna be in zero and what's positive will be one and

1416
01:15:59,000 --> 01:16:03,000
what's negative will be zero. Why not? Any other idea how to

1417
01:16:03,000 --> 01:16:07,000
transform this? Something which outputs minus infinity plus

1418
01:16:07,000 --> 01:16:09,000
infinity is something which is going to be zero or one. You

1419
01:16:09,000 --> 01:16:10,000
first, you second.

1420
01:16:10,000 --> 01:16:14,000
Yeah, you could add some set. Also threshold, but you could

1421
01:16:14,000 --> 01:16:16,000
add some area of uncertainty.

1422
01:16:17,000 --> 01:16:19,000
Oh, you can add area. Okay, good area of uncertainty. How would

1423
01:16:19,000 --> 01:16:20,000
you do that?

1424
01:16:21,000 --> 01:16:26,000
Maybe randomize one area. So you get some noise from data.

1425
01:16:27,000 --> 01:16:32,000
I wouldn't go into noise of data. I wouldn't. Oops. I would

1426
01:16:32,000 --> 01:16:36,000
I wouldn't go there. I mean, randomization of data. It's nice

1427
01:16:36,000 --> 01:16:40,000
if you do if you do differential privacy. So if you want to

1428
01:16:40,000 --> 01:16:42,000
randomize data, come to my group. And you know, we can talk

1429
01:16:42,000 --> 01:16:44,000
about randomization, but I wouldn't go there. You had a

1430
01:16:44,000 --> 01:16:51,000
brand new softmax. Okay, so you know, softmax already, will it

1431
01:16:51,000 --> 01:16:55,000
work here for a binary output for just one single scalar

1432
01:16:55,000 --> 01:17:01,000
softmax is something else. Well, it will work. Yes, I guess it

1433
01:17:01,000 --> 01:17:05,000
will work. One over it will be it will do something but maybe

1434
01:17:05,000 --> 01:17:09,000
not what we really want. Exactly. Anyway, sorry, you and

1435
01:17:09,000 --> 01:17:10,000
then I'll go over. Yes.

1436
01:17:12,000 --> 01:17:19,000
saturation function. Okay, what is it? Oh, yeah. So you would

1437
01:17:19,000 --> 01:17:23,000
somehow make a function which does this mapping by itself.

1438
01:17:25,000 --> 01:17:29,000
Yeah, okay. Exactly. So very popular function here is the

1439
01:17:29,000 --> 01:17:33,000
logistic function or sigmoid function, which is takes a real

1440
01:17:33,000 --> 01:17:37,000
number and outputs a real number and takes any real number as

1441
01:17:37,000 --> 01:17:41,000
inputs and produces exactly values between zero and one.

1442
01:17:42,000 --> 01:17:45,000
This is this is a saturation function is what you want. So

1443
01:17:45,000 --> 01:17:49,000
we're mapping through the sigmoid function, everything

1444
01:17:50,000 --> 01:17:56,000
into into this interval. Okay. There's other functions, but

1445
01:17:56,000 --> 01:18:01,000
this one is like the mainstream sigmoid, like mapping everything

1446
01:18:01,000 --> 01:18:06,000
into between zero and one. And it has this form. And I really

1447
01:18:06,000 --> 01:18:11,000
want you to know this. Okay, sigmoid, you should, you should

1448
01:18:11,000 --> 01:18:13,000
know, see what if you say like, I had deep learning for NLP and

1449
01:18:13,000 --> 01:18:17,000
ask what's the sigmoid? I'm not really sure the formula I can

1450
01:18:17,000 --> 01:18:23,000
look it up. No, no, no, you have to know this. Okay. So what is

1451
01:18:23,000 --> 01:18:28,000
it? What is interesting on this function is that it has a it has

1452
01:18:28,000 --> 01:18:31,000
a meaning. And I'll come to the meaning later on. But maybe the

1453
01:18:31,000 --> 01:18:34,000
first thing we put a sigmoid there. Okay, so we had this

1454
01:18:34,000 --> 01:18:36,000
output of this function, and then we put it through the

1455
01:18:36,000 --> 01:18:40,000
sigmoid. So what do we what do we have to know about a sigmoid

1456
01:18:40,000 --> 01:18:44,000
function as well? If we want to plug it into something, some

1457
01:18:44,000 --> 01:18:46,000
minimization, what do we need of the sigmoid? What do we need to

1458
01:18:46,000 --> 01:18:52,000
know? We need to know the derivative of this function.

1459
01:18:52,000 --> 01:18:56,000
Exactly. Yeah. So little bit of homework, derivatives, blah,

1460
01:18:56,000 --> 01:18:59,000
blah, blah, we end up with something which is very nice.

1461
01:18:59,000 --> 01:19:03,000
Actually, the derivative of the sigmoid, it's the value of the

1462
01:19:03,000 --> 01:19:06,000
sigmoid times one minus the value of the sigmoid. So there

1463
01:19:06,000 --> 01:19:10,000
is the computation will be like, easy, because you know the value

1464
01:19:10,000 --> 01:19:13,000
already. And there is no extra, you know, exponentiation on

1465
01:19:13,000 --> 01:19:16,000
whatever. So this is very nice computation. It's very

1466
01:19:16,000 --> 01:19:21,000
convenient. Okay, so we have this sigmoid, and we're going to

1467
01:19:21,000 --> 01:19:24,000
plug everything together. Okay, any question to the sigmoid

1468
01:19:24,000 --> 01:19:31,000
function? So yeah, anyone? No, it's clear. I mean, we're taking

1469
01:19:31,000 --> 01:19:34,000
everything and plug it between one and one and zero, zero and

1470
01:19:34,000 --> 01:19:39,000
one. Okay. And it's nicely centered around zero. And it has

1471
01:19:39,000 --> 01:19:43,000
this beautiful derivative, which means at any point we have

1472
01:19:43,000 --> 01:19:45,000
derivative. So here, the more to the right you go, the derivatives

1473
01:19:45,000 --> 01:19:49,000
will be zero. And here the derivatives will be zero. And

1474
01:19:49,000 --> 01:19:52,000
here the derivative will be roughly one and so on. So it's

1475
01:19:52,000 --> 01:19:53,000
nice later, you know, differentiable.

1476
01:19:53,000 --> 01:19:56,000
Is it computing the sigmoid function itself is being

1477
01:19:56,000 --> 01:19:59,000
quantified? So you need an exponentiation?

1478
01:19:59,000 --> 01:20:02,000
You need just one exponentiation. So what is, how

1479
01:20:02,000 --> 01:20:05,000
do you compute exponentiation? What is, what is, okay, what is

1480
01:20:05,000 --> 01:20:10,000
what is x of x? How do you compute this?

1481
01:20:15,000 --> 01:20:17,000
It's e to the power of x, but how do you compute e to the

1482
01:20:17,000 --> 01:20:18,000
power of x?

1483
01:20:21,000 --> 01:20:21,000
Approximation?

1484
01:20:22,000 --> 01:20:23,000
Yes, which is?

1485
01:20:27,000 --> 01:20:27,000
Series?

1486
01:20:28,000 --> 01:20:34,000
Yes, it's a series. Okay. So we're going to have a sum of.

1487
01:20:37,000 --> 01:20:48,000
Yeah. Okay. I guess it's one plus x over n, n from n is zero

1488
01:20:48,000 --> 01:20:51,000
to infinity. Is it somebody, somebody can look it up? Is it

1489
01:20:51,000 --> 01:20:54,000
correct? No.

1490
01:20:58,000 --> 01:21:02,000
No, wait a second. This will be a limit. n goes to infinity.

1491
01:21:03,000 --> 01:21:06,000
This is correct. And there's a sum and it's different. It's,

1492
01:21:06,000 --> 01:21:13,000
it's okay. The sum will be, what is it? K over k to n over n

1493
01:21:13,000 --> 01:21:17,000
factorial, right? Yeah. Okay. Yeah. So you can, you can do

1494
01:21:17,000 --> 01:21:20,000
either one of those. Right. So it won't be, it will be hard.

1495
01:21:28,000 --> 01:21:30,000
So this is easy and we have this as well. Yes. You have a

1496
01:21:30,000 --> 01:21:31,000
question.

1497
01:21:37,000 --> 01:21:41,000
Why? Okay. The question is why, why did I put t here? Right.

1498
01:21:41,000 --> 01:21:44,000
What is t? So I put t here just not to confuse with anything

1499
01:21:44,000 --> 01:21:47,000
else because it's just a function which takes real and

1500
01:21:47,000 --> 01:21:50,000
outputs real. The actual input will be, thank you for the

1501
01:21:50,000 --> 01:21:56,000
bridge, will be the output of our linear function. Okay. Yes.

1502
01:21:56,000 --> 01:22:00,000
Thank you. This is great. It's really like, you know, it's a

1503
01:22:00,000 --> 01:22:06,000
dialogue. Exactly. So here let's, let's put it into, into

1504
01:22:06,000 --> 01:22:09,000
computational graphs. So what, what we had so far, this was

1505
01:22:09,000 --> 01:22:16,000
our linear function, this vector input times the vector plus an

1506
01:22:16,000 --> 01:22:21,000
offset. And now we plug it into the, into the sigmoid, right? So

1507
01:22:21,000 --> 01:22:23,000
this will be the parameter of the, the, the input of the

1508
01:22:23,000 --> 01:22:27,000
sigmoid. And we can build it as this computational graph,

1509
01:22:27,000 --> 01:22:32,000
which was beautiful. And if this is the same, oh, actually,

1510
01:22:32,000 --> 01:22:34,000
this is a very same, you know, computational graph we had in

1511
01:22:34,000 --> 01:22:38,000
the last lecture. You basically, each node is a function and has

1512
01:22:38,000 --> 01:22:42,000
some, some arguments. So this is a function of the linear, this

1513
01:22:42,000 --> 01:22:46,000
is the linear function and the inputs are the vector X, the

1514
01:22:46,000 --> 01:22:51,000
vector of the parameters and here the, the offset of B coming

1515
01:22:51,000 --> 01:22:53,000
here and the output of that goes through, through the

1516
01:22:53,000 --> 01:22:58,000
sigmoid and coming out this, this Y hat. Why is it the hat?

1517
01:22:58,000 --> 01:23:00,000
We're because this is the prediction. This is not a true

1518
01:23:00,000 --> 01:23:04,000
label. True label is just the Y. This is Y hat. So it's not the

1519
01:23:04,000 --> 01:23:07,000
same thing. It's like the prediction, right? Oh, this is

1520
01:23:07,000 --> 01:23:11,000
cool. So we have this computational graph. I'll finish

1521
01:23:11,000 --> 01:23:18,000
in three minutes. Okay. Now what do we need to do? Okay. So we

1522
01:23:18,000 --> 01:23:20,000
have this output of the sigmoids and we are doing the binary

1523
01:23:20,000 --> 01:23:24,000
classification. So what's coming out of the sigmoids is

1524
01:23:24,000 --> 01:23:28,000
values between zero and one. So how do you know, like, what is

1525
01:23:28,000 --> 01:23:32,000
going to be zero, what is going to be one? Yeah, we're going to

1526
01:23:32,000 --> 01:23:34,000
use a threshold. So somebody said your threshold as well. I

1527
01:23:34,000 --> 01:23:37,000
mean, we have no threshold as well for the, for the sigmoid.

1528
01:23:37,000 --> 01:23:40,000
So we're going to say what's coming out of here, if it's

1529
01:23:40,000 --> 01:23:44,000
bigger than 0.5, it's going to be one. And if it's smaller than

1530
01:23:44,000 --> 01:23:49,000
0.5, it's going to be zero. If it's exactly 0.5, we throw a

1531
01:23:49,000 --> 01:23:52,000
coin, something like that. No, well, it's arbitrary decision.

1532
01:23:52,000 --> 01:23:56,000
It could be like greater than equal. So why is it so? Okay.

1533
01:23:56,000 --> 01:23:59,000
Well, let's come back to this sigmoid function, right? So here,

1534
01:24:00,000 --> 01:24:03,000
yeah, it makes sense. Like this is an odd function. And now

1535
01:24:03,000 --> 01:24:06,000
just in the middle, we say, oh, here's the cut. So if it's

1536
01:24:06,000 --> 01:24:11,000
larger than 0.5, we're going to say it's one and it's zero

1537
01:24:11,000 --> 01:24:15,000
otherwise, right? It makes a lot of sense. But now there's a

1538
01:24:15,000 --> 01:24:19,000
very cool thing about a sigmoid because it's not, you know, if

1539
01:24:19,000 --> 01:24:22,000
we had like a threshold in function, which would be like,

1540
01:24:23,000 --> 01:24:32,000
oh, I can use colors. Maybe here, here would be, and then a

1541
01:24:32,000 --> 01:24:38,000
step and here. So this would be like one and zero. Yeah. This

1542
01:24:38,000 --> 01:24:41,000
is threshold as well. So if it's bigger than, oh, it makes

1543
01:24:41,000 --> 01:24:44,000
no sense. I'm sorry. No, no, no. Let me just roll back. I'll

1544
01:24:44,000 --> 01:24:47,000
cut it off from the video. No, no, no, no. So this is nice

1545
01:24:47,000 --> 01:24:54,000
because it has also the value of this y hat as a natural

1546
01:24:54,000 --> 01:24:58,000
interpretation. And it's saying as the probability of

1547
01:24:58,000 --> 01:25:04,000
prediction is equal to one given the input x. So again, the

1548
01:25:04,000 --> 01:25:09,000
sigmoid output here is the probability that y is one given

1549
01:25:09,000 --> 01:25:15,000
x. Does it make sense? If I'm coming back to this slide, if

1550
01:25:15,000 --> 01:25:20,000
I'm here, it's telling me, yeah, it's like 80% probability

1551
01:25:20,000 --> 01:25:26,000
that I'm, you know, I'm close to one and 20% probability that

1552
01:25:26,000 --> 01:25:30,000
I'm close to zero. So it's like natural interpretation is

1553
01:25:30,000 --> 01:25:34,000
conditional probability. So the output is like, oh, given the,

1554
01:25:34,000 --> 01:25:38,000
given the feature vector x, the probability of, you know, the

1555
01:25:38,000 --> 01:25:43,000
output being one is this output. So you can use it for decision,

1556
01:25:44,000 --> 01:25:49,000
make a cut after half point five, or having also like

1557
01:25:49,000 --> 01:25:53,000
confidence of the model a little bit. Right? So if the value is

1558
01:25:53,000 --> 01:25:58,000
something like 0.55, the model is not really sure. If it, if it

1559
01:25:58,000 --> 01:26:02,000
outputs like 0.99, then the model kind of knows.

1560
01:26:02,000 --> 01:26:11,000
The value will be zero. So the value of the sigmoid will be

1561
01:26:12,000 --> 01:26:19,000
zero. Oh, this, okay. So it's coming zero coming in. So the

1562
01:26:19,000 --> 01:26:24,000
value coming in will be zero here and you end up with 0.5.

1563
01:26:25,000 --> 01:26:30,000
Yeah, that's possible. Yeah, exactly. I mean, you can do, you

1564
01:26:30,000 --> 01:26:34,000
can make like arbitrary choice. You say either, yeah, it's a, so

1565
01:26:34,000 --> 01:26:41,000
it could be greater or equal to 0.5, then it's one, or it could

1566
01:26:41,000 --> 01:26:47,000
be 0.5. It's going to be zero. It's up to you. Or you say like,

1567
01:26:47,000 --> 01:26:51,000
I can't tell you can play around with the value. Okay. Any other

1568
01:26:51,000 --> 01:26:58,000
question? Okay, good. So a small recap, I mean, there's more, but

1569
01:26:58,000 --> 01:27:00,000
it will, we'll do that next, next lecture. So let me just

1570
01:27:00,000 --> 01:27:04,000
recap what we had before. Oops. And there's just a slight

1571
01:27:04,000 --> 01:27:12,000
rush. So tokenization is tricky. Language is tricky as well. I

1572
01:27:12,000 --> 01:27:14,000
mean, language is tricky and tokenization is tricky because

1573
01:27:14,000 --> 01:27:16,000
what's a word and how do you define it? And so on, but it's

1574
01:27:16,000 --> 01:27:19,000
important. We learned the simplest representation as a

1575
01:27:19,000 --> 01:27:23,000
back of word features. So this is something you should kind of

1576
01:27:23,000 --> 01:27:26,000
take away with you back of word features. This is like the most

1577
01:27:26,000 --> 01:27:30,000
simple thing of representing language, throwing into a bag

1578
01:27:30,000 --> 01:27:33,000
and making vector out of it. And we learned that we can do

1579
01:27:33,000 --> 01:27:39,000
binary classification as a linear function of words and

1580
01:27:39,000 --> 01:27:45,000
the sigmoid over that. And this is something we learn next time.

1581
01:27:45,000 --> 01:27:50,000
Any other questions so far? Good. Thanks a lot. See you in a

1582
01:27:50,000 --> 01:27:55,000
week.

