\begin{frame}
\titlepage
\end{frame}
\begin{frame}{This lecture}
\vspace*{1cm}
\begin{itemize}
\item training as optimization
\item backpropagation
\item language modeling
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{./loss_and_regularization}
\input{./training_as_optimization}
\input{./language_models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Summary}
    \begin{itemize}
        \item training as optimization of a loss function
        \item common loss functions and regularization terms
        \item gradient descent (GD, SGD): A general technique for optimization
        \item backprop(agation): An algorithm for deriving gradients in neural models, once  gradients are determined we can train a model with SGD
        \item (Neural) Language Models (LMs) 
    \end{itemize}
\end{frame}
\begin{frame}[c]
\begin{center}
\LARGE{Thank You!}
\end{center}
\end{frame}

